{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a905d2",
   "metadata": {
    "papermill": {
     "duration": 0.006334,
     "end_time": "2025-12-24T14:24:40.520247",
     "exception": false,
     "start_time": "2025-12-24T14:24:40.513913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **<span style=\"color: green;\">Predictive Regression Tool Using Gradio</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf2635",
   "metadata": {
    "papermill": {
     "duration": 0.005319,
     "end_time": "2025-12-24T14:24:40.531035",
     "exception": false,
     "start_time": "2025-12-24T14:24:40.525716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://i.imgur.com/spUaGoh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9615ec33",
   "metadata": {
    "papermill": {
     "duration": 0.005067,
     "end_time": "2025-12-24T14:24:40.541281",
     "exception": false,
     "start_time": "2025-12-24T14:24:40.536214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Medical Insurance Cost**\n",
    "---\n",
    "![](https://storage.googleapis.com/kaggle-datasets-images/8129551/12853160/83b336ea7f928c215b00bfb0681810f1/dataset-cover.jpg?t=2025-08-24-12-28-03)\n",
    "\n",
    "*(https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)*\n",
    "\n",
    "\n",
    "For Assessment 2, we are required to solve a Machine Learning problem of any type. For this project, I decided to work with a Regression Task. We were also instructed to use Gradio to work with the Machine Learning Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2b070",
   "metadata": {
    "papermill": {
     "duration": 0.005228,
     "end_time": "2025-12-24T14:24:40.551744",
     "exception": false,
     "start_time": "2025-12-24T14:24:40.546516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.1 Importing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a019caa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:40.564213Z",
     "iopub.status.busy": "2025-12-24T14:24:40.563410Z",
     "iopub.status.idle": "2025-12-24T14:24:49.629044Z",
     "shell.execute_reply": "2025-12-24T14:24:49.628214Z"
    },
    "papermill": {
     "duration": 9.073659,
     "end_time": "2025-12-24T14:24:49.630656",
     "exception": false,
     "start_time": "2025-12-24T14:24:40.556997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cfcb5",
   "metadata": {
    "papermill": {
     "duration": 0.005184,
     "end_time": "2025-12-24T14:24:49.641344",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.636160",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.2 Printing CSV and Data Checking**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea8348a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:49.653836Z",
     "iopub.status.busy": "2025-12-24T14:24:49.652800Z",
     "iopub.status.idle": "2025-12-24T14:24:49.703497Z",
     "shell.execute_reply": "2025-12-24T14:24:49.702616Z"
    },
    "papermill": {
     "duration": 0.058133,
     "end_time": "2025-12-24T14:24:49.704768",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.646635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n",
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic = pd.read_csv('/kaggle/input/medical-insurance-cost-dataset/insurance.csv')\n",
    "print(mic.shape)\n",
    "print(mic.columns)\n",
    "mic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57654d1b",
   "metadata": {
    "papermill": {
     "duration": 0.005455,
     "end_time": "2025-12-24T14:24:49.716155",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.710700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 1338 rows, and seven columns with the categories: age, sex, bmi, children, smoker, region, and charges. Since ML trains on numerical data, the categorical features will have to be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c13ab2",
   "metadata": {
    "papermill": {
     "duration": 0.005833,
     "end_time": "2025-12-24T14:24:49.727382",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.721549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.21 Cleaning Data**\n",
    "---\n",
    "It is still good to check if any cells have missing or unsupported data. The isna().sum() methods from pandas are used together to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5507b7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:49.739685Z",
     "iopub.status.busy": "2025-12-24T14:24:49.739368Z",
     "iopub.status.idle": "2025-12-24T14:24:49.746561Z",
     "shell.execute_reply": "2025-12-24T14:24:49.745709Z"
    },
    "papermill": {
     "duration": 0.015233,
     "end_time": "2025-12-24T14:24:49.748002",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.732769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142fd61",
   "metadata": {
    "papermill": {
     "duration": 0.005556,
     "end_time": "2025-12-24T14:24:49.759176",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.753620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.3 Regression Task**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf176f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:49.771659Z",
     "iopub.status.busy": "2025-12-24T14:24:49.771325Z",
     "iopub.status.idle": "2025-12-24T14:24:50.159283Z",
     "shell.execute_reply": "2025-12-24T14:24:50.158502Z"
    },
    "papermill": {
     "duration": 0.396253,
     "end_time": "2025-12-24T14:24:50.160866",
     "exception": false,
     "start_time": "2025-12-24T14:24:49.764613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mic.drop('charges', axis=1)\n",
    "X = pd.get_dummies(X, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "y = mic['charges']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "LR = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "DTR = DecisionTreeRegressor().fit(train_X, train_y)\n",
    "\n",
    "RF = RandomForestRegressor().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49627dbc",
   "metadata": {
    "papermill": {
     "duration": 0.005609,
     "end_time": "2025-12-24T14:24:50.172173",
     "exception": false,
     "start_time": "2025-12-24T14:24:50.166564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.4 Model Performance & Optimization**\n",
    "---\n",
    "The accuracy of the models have to be determined to see if the tool is reliable and ready to be deployed for people to use. The provided function works with sklearn's imported methods, evaluating the different models that were previously named. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818dbca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:50.184969Z",
     "iopub.status.busy": "2025-12-24T14:24:50.184364Z",
     "iopub.status.idle": "2025-12-24T14:24:50.241588Z",
     "shell.execute_reply": "2025-12-24T14:24:50.240526Z"
    },
    "papermill": {
     "duration": 0.065436,
     "end_time": "2025-12-24T14:24:50.243140",
     "exception": false,
     "start_time": "2025-12-24T14:24:50.177704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Linear Regression\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      " R²: 0.742\n",
      " MAE: 4,208.23\n",
      " MSE: 37,277,681.70\n",
      " RMSE: 6,105.55\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.784\n",
      "MAE: 4,181.19\n",
      "MSE: 33,596,915.85\n",
      "RMSE: 5,796.28\n",
      "\u001b[4m\n",
      "Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.998\n",
      "MAE: 29.57\n",
      "MSE: 244,239.55\n",
      "RMSE: 494.21\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.723\n",
      "MAE: 3,189.38\n",
      "MSE: 42,935,940.31\n",
      "RMSE: 6,552.55\n",
      "\u001b[4m\n",
      "Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.976\n",
      "MAE: 1,069.32\n",
      "MSE: 3,500,578.50\n",
      "RMSE: 1,870.98\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.868\n",
      "MAE: 2,536.30\n",
      "MSE: 20,516,904.74\n",
      "RMSE: 4,529.56\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    r2 = r2_score(y, preds)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    return r2, mae, mse, rmse\n",
    "\n",
    "# Linear Regression ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nLinear Regression\" + \"\\x1B[0m\") \n",
    "r2_lr_tr, mae_lr_tr, mse_lr_tr, rmse_lr_tr = evaluate(LR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\" R²: {r2_lr_tr:.3f}\") \n",
    "print(f\" MAE: {mae_lr_tr:,.2f}\") \n",
    "print(f\" MSE: {mse_lr_tr:,.2f}\") \n",
    "print(f\" RMSE: {rmse_lr_tr:,.2f}\")\n",
    "\n",
    "r2_lr, mae_lr, mse_lr, rmse_lr = evaluate(LR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_lr:.3f}\") \n",
    "print(f\"MAE: {mae_lr:,.2f}\") \n",
    "print(f\"MSE: {mse_lr:,.2f}\")\n",
    "print(f\"RMSE: {rmse_lr:,.2f}\")\n",
    "    \n",
    "# Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nDecision Tree\" + \"\\x1B[0m\") \n",
    "r2_dt_tr, mae_dt_tr, mse_dt_tr, rmse_dt_tr = evaluate(DTR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_dt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_dt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt_tr:,.2f}\")\n",
    "\n",
    "r2_dt, mae_dt, mse_dt, rmse_dt = evaluate(DTR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt:.3f}\") \n",
    "print(f\"MAE: {mae_dt:,.2f}\") \n",
    "print(f\"MSE: {mse_dt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt:,.2f}\")\n",
    "\n",
    "# Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nRandom Forest\" + \"\\x1B[0m\") \n",
    "r2_rf_tr, mae_rf_tr, mse_rf_tr, rmse_rf_tr = evaluate(RF, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_rf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_rf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_rf_tr:,.2f}\")\n",
    "\n",
    "r2_rf, mae_rf, mse_rf, rmse_rf = evaluate(RF, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf:.3f}\") \n",
    "print(f\"MAE: {mae_rf:,.2f}\") \n",
    "print(f\"MSE: {mse_rf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_rf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dbb74b",
   "metadata": {
    "papermill": {
     "duration": 0.005795,
     "end_time": "2025-12-24T14:24:50.255193",
     "exception": false,
     "start_time": "2025-12-24T14:24:50.249398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.41 Optimization**\n",
    "---\n",
    "With evaluation metrics, lower values are better for MAE, MSE, and RMSE. As for the R² score, it should be higher. Out of the models evaluated so far, Random Forest had the best performance out of the box, with the Decision Tree model performing the least. The Decision Tree and Random Forest models will be optimized as they can be tuned with hyperparameters. The Bayesian Optimization library is used after installing it through the console. Bayesian Optimization was used over Grid Search and Random Search to effectively find the optimal hyperparameters for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608240f",
   "metadata": {
    "papermill": {
     "duration": 0.005637,
     "end_time": "2025-12-24T14:24:50.266498",
     "exception": false,
     "start_time": "2025-12-24T14:24:50.260861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41a Decision Tree Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e76ea20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:50.279106Z",
     "iopub.status.busy": "2025-12-24T14:24:50.278763Z",
     "iopub.status.idle": "2025-12-24T14:24:55.798171Z",
     "shell.execute_reply": "2025-12-24T14:24:55.797173Z"
    },
    "papermill": {
     "duration": 5.527812,
     "end_time": "2025-12-24T14:24:55.799901",
     "exception": false,
     "start_time": "2025-12-24T14:24:50.272089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.46e+07\u001b[39m | \u001b[39m8.1162622\u001b[39m | \u001b[39m19.112857\u001b[39m | \u001b[39m14.907884\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-3.28e+07\u001b[39m | \u001b[39m12.374511\u001b[39m | \u001b[39m4.8083355\u001b[39m | \u001b[39m3.9638958\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.57e+07\u001b[39m | \u001b[39m2.1035886\u001b[39m | \u001b[39m17.591170\u001b[39m | \u001b[39m12.421185\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.42e+07\u001b[39m | \u001b[35m14.453378\u001b[39m | \u001b[35m2.3705208\u001b[39m | \u001b[35m19.428287\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.96e+07\u001b[39m | \u001b[39m16.816410\u001b[39m | \u001b[39m5.8221039\u001b[39m | \u001b[39m4.4546743\u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-2.39e+07\u001b[39m | \u001b[35m11.385296\u001b[39m | \u001b[35m10.542765\u001b[39m | \u001b[35m20.0     \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m14.138448\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.55e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m9.9460183\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.42e+07\u001b[39m | \u001b[39m11.982222\u001b[39m | \u001b[39m8.9658312\u001b[39m | \u001b[39m19.883575\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m5.4251767\u001b[39m | \u001b[39m14.584147\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.49e+07\u001b[39m | \u001b[39m13.464222\u001b[39m | \u001b[39m13.229258\u001b[39m | \u001b[39m12.135924\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.41e+07\u001b[39m | \u001b[39m15.859325\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m18.526555\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.92e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m16.698567\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.54e+07\u001b[39m | \u001b[39m11.673448\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m8.5865338\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m-2.33e+07\u001b[39m | \u001b[35m5.8154771\u001b[39m | \u001b[35m12.320651\u001b[39m | \u001b[35m10.940210\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-4.40e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.48e+07\u001b[39m | \u001b[39m14.332692\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m11.971412\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.62e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m12.101485\u001b[39m | \u001b[39m8.5965694\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m18.205336\u001b[39m | \u001b[39m8.1242594\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.0300918\u001b[39m | \u001b[39m16.728894\u001b[39m | \u001b[39m10.570303\u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m11.323618\u001b[39m | \u001b[39m7.4461229\u001b[39m | \u001b[39m13.089682\u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.5918264\u001b[39m | \u001b[39m13.326961\u001b[39m | \u001b[39m15.063144\u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m14.245678\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m13.294957\u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m14.769305\u001b[39m | \u001b[39m14.560632\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 10}\n",
      "Best Score (Bayesian Optimization): -23326594.469013788\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from GeeksforGeeks, using bayesian optimization (https://www.geeksforgeeks.org/machine-learning/how-to-tune-a-decision-tree-in-hyperparameter-tuning/)\n",
    "def dt_mic(max_depth, min_samples_split, min_samples_leaf):\n",
    "    estimator = DecisionTreeRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5) # Minimizing MSE is equivalent to maximizing negative-MSE\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20)\n",
    "}\n",
    "\n",
    "dt_optimizer = BayesianOptimization(\n",
    "    f=dt_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt_optimizer.maximize(n_iter=25, init_points=5)\n",
    "best_params_dt = dt_optimizer.max['params']\n",
    "best_params_dt['max_depth'] = int(best_params_dt['max_depth'])\n",
    "best_params_dt['min_samples_split'] = int(best_params_dt['min_samples_split'])\n",
    "best_params_dt['min_samples_leaf'] = int(best_params_dt['min_samples_leaf'])\n",
    "best_score_dt = dt_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_dt}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6784f",
   "metadata": {
    "papermill": {
     "duration": 0.010912,
     "end_time": "2025-12-24T14:24:55.826303",
     "exception": false,
     "start_time": "2025-12-24T14:24:55.815391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c862ac24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:55.849871Z",
     "iopub.status.busy": "2025-12-24T14:24:55.849523Z",
     "iopub.status.idle": "2025-12-24T14:24:55.869503Z",
     "shell.execute_reply": "2025-12-24T14:24:55.868821Z"
    },
    "papermill": {
     "duration": 0.033767,
     "end_time": "2025-12-24T14:24:55.871144",
     "exception": false,
     "start_time": "2025-12-24T14:24:55.837377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.867\n",
      "Optimized RMSE: 4,829.76\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Decision Tree Regressor\n",
    "DT_Bayes = DecisionTreeRegressor( \n",
    "    max_depth=best_params_dt['max_depth'], \n",
    "    min_samples_split=best_params_dt['min_samples_split'], \n",
    "    min_samples_leaf=best_params_dt['min_samples_leaf'], \n",
    "    random_state=42)\n",
    "\n",
    "DT_Bayes.fit(train_X, train_y)\n",
    "\n",
    "dt_mse_translate = -best_score_dt # Since the cross val score uses negative scoring, this turns it into a positive value\n",
    "dt_rmse_translate = np.sqrt(dt_mse_translate) # Square root of mse is rmse and is closer to the values used for medical insurance cost in $USD\n",
    "dt_preds = DT_Bayes.predict(val_X)\n",
    "dt_r2 = r2_score(val_y, dt_preds) \n",
    "\n",
    "print(f\"Optimized R²: {dt_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {dt_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fba67a",
   "metadata": {
    "papermill": {
     "duration": 0.006584,
     "end_time": "2025-12-24T14:24:55.886423",
     "exception": false,
     "start_time": "2025-12-24T14:24:55.879839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41b Random Forest Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a5f0f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:24:55.901353Z",
     "iopub.status.busy": "2025-12-24T14:24:55.900693Z",
     "iopub.status.idle": "2025-12-24T14:27:01.834724Z",
     "shell.execute_reply": "2025-12-24T14:27:01.833659Z"
    },
    "papermill": {
     "duration": 125.943153,
     "end_time": "2025-12-24T14:27:01.836301",
     "exception": false,
     "start_time": "2025-12-24T14:24:55.893148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_esti... | max_depth | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.36e+07\u001b[39m | \u001b[39m249.81604\u001b[39m | \u001b[39m29.014286\u001b[39m | \u001b[39m7.8559515\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m339.46339\u001b[39m | \u001b[39m13.120372\u001b[39m | \u001b[39m3.2479561\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.38e+07\u001b[39m | \u001b[39m123.23344\u001b[39m | \u001b[39m27.323522\u001b[39m | \u001b[39m6.8089200\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.32e+07\u001b[39m | \u001b[35m383.22903\u001b[39m | \u001b[35m10.411689\u001b[39m | \u001b[35m9.7592788\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m432.97705\u001b[39m | \u001b[39m14.246782\u001b[39m | \u001b[39m3.4545997\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-2.34e+07\u001b[39m | \u001b[39m383.12355\u001b[39m | \u001b[39m10.428747\u001b[39m | \u001b[39m8.6841783\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m387.52410\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.50203\u001b[39m | \u001b[39m16.670786\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m396.41384\u001b[39m | \u001b[39m14.198882\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m395.99091\u001b[39m | \u001b[39m25.168777\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m403.23208\u001b[39m | \u001b[39m21.595070\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.63557\u001b[39m | \u001b[39m27.715969\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m375.82364\u001b[39m | \u001b[39m25.009127\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.24790\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.88791\u001b[39m | \u001b[39m18.238178\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m367.98182\u001b[39m | \u001b[39m24.949440\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m382.25633\u001b[39m | \u001b[39m22.129411\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m369.21462\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m359.87025\u001b[39m | \u001b[39m10.365589\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m354.88643\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m355.82650\u001b[39m | \u001b[39m19.782845\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.37e+07\u001b[39m | \u001b[39m189.70758\u001b[39m | \u001b[39m10.207937\u001b[39m | \u001b[39m6.6337112\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.40e+07\u001b[39m | \u001b[39m499.62040\u001b[39m | \u001b[39m29.559066\u001b[39m | \u001b[39m5.2809506\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m287.73411\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m289.65078\u001b[39m | \u001b[39m15.960336\u001b[39m | \u001b[39m2.0068777\u001b[39m |\n",
      "| \u001b[35m26       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m278.84161\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[35m27       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m268.81017\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m271.92727\u001b[39m | \u001b[39m18.680327\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m266.62652\u001b[39m | \u001b[39m15.173725\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m374.99721\u001b[39m | \u001b[39m16.319748\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'n_estimators': 268, 'max_depth': 10, 'min_samples_split': 10}\n",
      "Best Score (Bayesian Optimization): -23110676.701853152\n"
     ]
    }
   ],
   "source": [
    "def rf_mic(n_estimators, max_depth, min_samples_split):\n",
    "    estimator = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        random_state=42\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 30),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "rf_optimizer = BayesianOptimization(\n",
    "    f=rf_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "best_params_rf = rf_optimizer.max['params']\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['min_samples_split'] = int(best_params_rf['min_samples_split'])\n",
    "best_score_rf = rf_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_rf}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7378aa",
   "metadata": {
    "papermill": {
     "duration": 0.008239,
     "end_time": "2025-12-24T14:27:01.853090",
     "exception": false,
     "start_time": "2025-12-24T14:27:01.844851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8b8da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:27:01.870982Z",
     "iopub.status.busy": "2025-12-24T14:27:01.870420Z",
     "iopub.status.idle": "2025-12-24T14:27:02.542250Z",
     "shell.execute_reply": "2025-12-24T14:27:02.541267Z"
    },
    "papermill": {
     "duration": 0.682493,
     "end_time": "2025-12-24T14:27:02.543743",
     "exception": false,
     "start_time": "2025-12-24T14:27:01.861250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.872\n",
      "Optimized RMSE: 4,807.36\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Random Forest Regressor\n",
    "RF_Bayes = RandomForestRegressor( \n",
    "    n_estimators=best_params_rf['n_estimators'], \n",
    "    max_depth=best_params_rf['max_depth'], \n",
    "    min_samples_split=best_params_rf['min_samples_split'], \n",
    "    random_state=42)\n",
    "\n",
    "RF_Bayes.fit(train_X, train_y)\n",
    "\n",
    "rf_mse_translate = -best_score_rf\n",
    "rf_rmse_translate = np.sqrt(rf_mse_translate)\n",
    "rf_preds = RF_Bayes.predict(val_X)\n",
    "rf_r2 = r2_score(val_y, rf_preds) \n",
    "\n",
    "print(f\"Optimized R²: {rf_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {rf_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3c48c",
   "metadata": {
    "papermill": {
     "duration": 0.008276,
     "end_time": "2025-12-24T14:27:02.560535",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.552259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Optimized Models Performance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9441aa0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:27:02.578559Z",
     "iopub.status.busy": "2025-12-24T14:27:02.577732Z",
     "iopub.status.idle": "2025-12-24T14:27:02.644489Z",
     "shell.execute_reply": "2025-12-24T14:27:02.643401Z"
    },
    "papermill": {
     "duration": 0.077321,
     "end_time": "2025-12-24T14:27:02.645904",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.568583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Optimized Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.873\n",
      "MAE: 2,420.59\n",
      "MSE: 18,311,904.31\n",
      "RMSE: 4,279.24\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.867\n",
      "MAE: 2,646.49\n",
      "MSE: 20,594,594.98\n",
      "RMSE: 4,538.13\n",
      "\u001b[4m\n",
      "Optimized Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.924\n",
      "MAE: 1,842.33\n",
      "MSE: 10,936,379.26\n",
      "RMSE: 3,307.02\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.872\n",
      "MAE: 2,542.78\n",
      "MSE: 19,878,928.21\n",
      "RMSE: 4,458.58\n"
     ]
    }
   ],
   "source": [
    "# Optimized Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Decision Tree\" + \"\\x1B[0m\") \n",
    "r2_odt_tr, mae_odt_tr, mse_odt_tr, rmse_odt_tr = evaluate(DT_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_odt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_odt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt_tr:,.2f}\")\n",
    "\n",
    "r2_odt, mae_odt, mse_odt, rmse_odt = evaluate(DT_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt:.3f}\") \n",
    "print(f\"MAE: {mae_odt:,.2f}\") \n",
    "print(f\"MSE: {mse_odt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt:,.2f}\")\n",
    "\n",
    "# Optimized Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Random Forest\" + \"\\x1B[0m\") \n",
    "r2_orf_tr, mae_orf_tr, mse_orf_tr, rmse_orf_tr = evaluate(RF_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_orf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_orf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_orf_tr:,.2f}\")\n",
    "\n",
    "r2_orf, mae_orf, mse_orf, rmse_orf = evaluate(RF_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf:.3f}\") \n",
    "print(f\"MAE: {mae_orf:,.2f}\") \n",
    "print(f\"MSE: {mse_orf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_orf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563afc97",
   "metadata": {
    "papermill": {
     "duration": 0.008119,
     "end_time": "2025-12-24T14:27:02.662497",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.654378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.5 Functions for Gradio**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769bdd9",
   "metadata": {
    "papermill": {
     "duration": 0.008157,
     "end_time": "2025-12-24T14:27:02.679290",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.671133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.51 Function 1**\n",
    "---\n",
    "Since the user will have to input categorical features alongside numerical inputs, they will have to be formatted accordingly. In this function, a copy of the original dataset is made, and the features are filled in correspondingly. Since age, bmi, and children are numerical features, they already work fine with the function. However, sex, smoker, and region are categorical features, which means they have to be numerical for the function to work. The problem is bypassed by checking if the user input matches the previously one-hot encoded categorical features, like sex, which is turned into sex_female or sex_male by pandas. Now that the features are numerical, they can be used in the function for model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e7a226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:27:02.697212Z",
     "iopub.status.busy": "2025-12-24T14:27:02.696687Z",
     "iopub.status.idle": "2025-12-24T14:27:02.702441Z",
     "shell.execute_reply": "2025-12-24T14:27:02.701591Z"
    },
    "papermill": {
     "duration": 0.016555,
     "end_time": "2025-12-24T14:27:02.703991",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.687436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_input(age, sex, bmi, children, smoker, region):\n",
    "    input_row = pd.DataFrame(0, index=[0], columns=X.columns)\n",
    "\n",
    "    input_row['age'] = age\n",
    "    input_row['bmi'] = bmi\n",
    "    input_row['children'] = children\n",
    "\n",
    "    # one-hot categorical\n",
    "    col = f\"sex_{sex}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"smoker_{smoker}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"region_{region}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    return input_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd563ec3",
   "metadata": {
    "papermill": {
     "duration": 0.008163,
     "end_time": "2025-12-24T14:27:02.720468",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.712305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.52 Function 2**\n",
    "---\n",
    "This section contains the prediction function that Gradio will use. In the function, the categorical features are turned into lowercase versions to match the dataset columns. The previous function is then called, which lets the rest of the function work as explained earlier. The rest of the code is now just an if-else statement checking what model the user has chosen, wherein it will then use sklearn's predict method using the built inputs with the type of model it is for. The predictions are the target feature in the dataset, which is \"charges\", or the Medical Insurance Cost that the tool is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e91688be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:27:02.738345Z",
     "iopub.status.busy": "2025-12-24T14:27:02.738054Z",
     "iopub.status.idle": "2025-12-24T14:27:02.744526Z",
     "shell.execute_reply": "2025-12-24T14:27:02.743609Z"
    },
    "papermill": {
     "duration": 0.017297,
     "end_time": "2025-12-24T14:27:02.745933",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.728636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, age, sex, bmi, children, smoker, region):\n",
    "    # Dataset columns are lowercase, but user input first letters are uppercased for formatting aesthetics\n",
    "    sex = sex.lower()\n",
    "    smoker = smoker.lower()\n",
    "    region = region.lower()\n",
    "\n",
    "    input_df = build_input(age, sex, bmi, children, smoker, region)\n",
    "    \n",
    "    if model == 'Linear Regression':\n",
    "        preds = LR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Decision Tree':\n",
    "        preds = DTR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Random Forest':\n",
    "        preds = RF.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized DT':\n",
    "        preds = DT_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized RF':\n",
    "        preds = RF_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e8a0f3",
   "metadata": {
    "papermill": {
     "duration": 0.00804,
     "end_time": "2025-12-24T14:27:02.762402",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.754362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.6 Gradio Interface**\n",
    "---\n",
    "To use the functions through a GUI, Gradio will be used as it provides a clean interface for deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211b3f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T14:27:02.780601Z",
     "iopub.status.busy": "2025-12-24T14:27:02.779854Z",
     "iopub.status.idle": "2025-12-24T14:27:05.402208Z",
     "shell.execute_reply": "2025-12-24T14:27:05.401315Z"
    },
    "papermill": {
     "duration": 2.633135,
     "end_time": "2025-12-24T14:27:05.403563",
     "exception": false,
     "start_time": "2025-12-24T14:27:02.770428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://f5bbddcaa88bc11354.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f5bbddcaa88bc11354.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    gr.Dropdown([\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Optimized DT\", \"Optimized RF\"], value=\"Optimized RF\", label=\"Model\"),\n",
    "    gr.Number(label=\"Age\", minimum=0),\n",
    "    gr.Dropdown([\"Male\", \"Female\"], label=\"Sex\"),\n",
    "    gr.Number(label=\"BMI\"),\n",
    "    gr.Number(label=\"Number of children\"),\n",
    "    gr.Dropdown([\"No\", \"Yes\"], label=\"Smoker\"),\n",
    "    gr.Dropdown([\"Northeast\", \"Northwest\", \"Southeast\", \"Southwest\"], label=\"Location\")\n",
    "]\n",
    "\n",
    "outputs = gr.Textbox(label=\"Predicted Charge\")\n",
    "\n",
    "css = \"\"\"\n",
    ".gradio-container{\n",
    "margin-top: 3rem !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "PredictiveTool = gr.Interface(\n",
    "    fn=predict, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    title=\"Medical Insurance Cost\",\n",
    "    theme=gr.themes.Soft(), # Different theme to change the look of the tool. The blue, monochromatic palette goes well with how medical/healthcare designs are generally represented.\n",
    "    css=css\n",
    ")\n",
    "PredictiveTool.launch(height=900) # Bigger Rendered HTML height for UX design so users do not have to scroll to use the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0833974",
   "metadata": {
    "papermill": {
     "duration": 0.009945,
     "end_time": "2025-12-24T14:27:05.422229",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.412284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Deliverables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14575091",
   "metadata": {
    "papermill": {
     "duration": 0.012916,
     "end_time": "2025-12-24T14:27:05.450765",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.437849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.1 Dataset Description**\n",
    "The dataset this ML problem is trained on is from the Medical Insurance Cost Dataset by Mosap Abdel-Ghany here on Kaggle (https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset). \n",
    "\n",
    "The dataset contains 1338 rows and 7 columns, with 4 numerical features and 3 categorical features. The dataset has already been cleaned beforehand so there are no invalid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8faab0",
   "metadata": {
    "papermill": {
     "duration": 0.008511,
     "end_time": "2025-12-24T14:27:05.468033",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.459522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.2 Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1668fe0",
   "metadata": {
    "papermill": {
     "duration": 0.008363,
     "end_time": "2025-12-24T14:27:05.485011",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.476648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.3 Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a09640",
   "metadata": {
    "papermill": {
     "duration": 0.008611,
     "end_time": "2025-12-24T14:27:05.502069",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.493458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.4 Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bfcdf9",
   "metadata": {
    "papermill": {
     "duration": 0.008506,
     "end_time": "2025-12-24T14:27:05.519181",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.510675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.5 Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677b87f",
   "metadata": {
    "papermill": {
     "duration": 0.008399,
     "end_time": "2025-12-24T14:27:05.535993",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.527594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "Initially, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a1fc1",
   "metadata": {
    "papermill": {
     "duration": 0.008549,
     "end_time": "2025-12-24T14:27:05.553099",
     "exception": false,
     "start_time": "2025-12-24T14:27:05.544550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8129551,
     "sourceId": 12853160,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 152.06216,
   "end_time": "2025-12-24T14:27:08.180552",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T14:24:36.118392",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
