{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b444760",
   "metadata": {
    "papermill": {
     "duration": 0.007089,
     "end_time": "2025-12-24T20:18:37.458375",
     "exception": false,
     "start_time": "2025-12-24T20:18:37.451286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **<span style=\"color: green;\">Predictive Regression Tool Using Gradio</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc687b35",
   "metadata": {
    "papermill": {
     "duration": 0.006064,
     "end_time": "2025-12-24T20:18:37.470385",
     "exception": false,
     "start_time": "2025-12-24T20:18:37.464321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://i.imgur.com/spUaGoh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240d26d",
   "metadata": {
    "papermill": {
     "duration": 0.005419,
     "end_time": "2025-12-24T20:18:37.481456",
     "exception": false,
     "start_time": "2025-12-24T20:18:37.476037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Medical Insurance Cost**\n",
    "---\n",
    "![](https://storage.googleapis.com/kaggle-datasets-images/8129551/12853160/83b336ea7f928c215b00bfb0681810f1/dataset-cover.jpg?t=2025-08-24-12-28-03)\n",
    "\n",
    "*(https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)*\n",
    "\n",
    "\n",
    "For Assessment 2, we are required to solve a Machine Learning problem of any type. For this project, I decided to work with a Regression Task. We were also instructed to use Gradio to work with the Machine Learning Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120ea75",
   "metadata": {
    "papermill": {
     "duration": 0.005286,
     "end_time": "2025-12-24T20:18:37.492233",
     "exception": false,
     "start_time": "2025-12-24T20:18:37.486947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.1 Importing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef9b2fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:37.505692Z",
     "iopub.status.busy": "2025-12-24T20:18:37.505063Z",
     "iopub.status.idle": "2025-12-24T20:18:48.199314Z",
     "shell.execute_reply": "2025-12-24T20:18:48.198217Z"
    },
    "papermill": {
     "duration": 10.703568,
     "end_time": "2025-12-24T20:18:48.201419",
     "exception": false,
     "start_time": "2025-12-24T20:18:37.497851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc77dd3",
   "metadata": {
    "papermill": {
     "duration": 0.005535,
     "end_time": "2025-12-24T20:18:48.212941",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.207406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.2 Printing CSV and Data Checking**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1edb4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:48.226027Z",
     "iopub.status.busy": "2025-12-24T20:18:48.224922Z",
     "iopub.status.idle": "2025-12-24T20:18:48.282959Z",
     "shell.execute_reply": "2025-12-24T20:18:48.282101Z"
    },
    "papermill": {
     "duration": 0.06607,
     "end_time": "2025-12-24T20:18:48.284318",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.218248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n",
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic = pd.read_csv('/kaggle/input/medical-insurance-cost-dataset/insurance.csv')\n",
    "print(mic.shape)\n",
    "print(mic.columns)\n",
    "mic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb4df7",
   "metadata": {
    "papermill": {
     "duration": 0.005841,
     "end_time": "2025-12-24T20:18:48.296240",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.290399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 1338 rows, and seven columns with the categories: age, sex, bmi, children, smoker, region, and charges. Since ML trains on numerical data, the categorical features will have to be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcdce4",
   "metadata": {
    "papermill": {
     "duration": 0.006592,
     "end_time": "2025-12-24T20:18:48.308901",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.302309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.21 Cleaning Data**\n",
    "---\n",
    "It is still good to check if any cells have missing or unsupported data. The isna().sum() methods from pandas are used together to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d708eab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:48.322937Z",
     "iopub.status.busy": "2025-12-24T20:18:48.321943Z",
     "iopub.status.idle": "2025-12-24T20:18:48.330526Z",
     "shell.execute_reply": "2025-12-24T20:18:48.329417Z"
    },
    "papermill": {
     "duration": 0.017445,
     "end_time": "2025-12-24T20:18:48.332147",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.314702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128312be",
   "metadata": {
    "papermill": {
     "duration": 0.005591,
     "end_time": "2025-12-24T20:18:48.343847",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.338256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.3 Regression Task**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d790ea0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:48.357527Z",
     "iopub.status.busy": "2025-12-24T20:18:48.356817Z",
     "iopub.status.idle": "2025-12-24T20:18:48.767597Z",
     "shell.execute_reply": "2025-12-24T20:18:48.766700Z"
    },
    "papermill": {
     "duration": 0.41995,
     "end_time": "2025-12-24T20:18:48.769376",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.349426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mic.drop('charges', axis=1)\n",
    "X = pd.get_dummies(X, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "y = mic['charges']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "LR = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "DTR = DecisionTreeRegressor().fit(train_X, train_y)\n",
    "\n",
    "RF = RandomForestRegressor().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964e1bc",
   "metadata": {
    "papermill": {
     "duration": 0.005597,
     "end_time": "2025-12-24T20:18:48.781130",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.775533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.4 Model Performance & Optimization**\n",
    "---\n",
    "The accuracy of the models have to be determined to see if the tool is reliable and ready to be deployed for people to use. The provided function works with sklearn's imported methods, evaluating the different models that were previously named. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e9d53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:48.794115Z",
     "iopub.status.busy": "2025-12-24T20:18:48.793498Z",
     "iopub.status.idle": "2025-12-24T20:18:48.850245Z",
     "shell.execute_reply": "2025-12-24T20:18:48.849570Z"
    },
    "papermill": {
     "duration": 0.06536,
     "end_time": "2025-12-24T20:18:48.852088",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.786728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Linear Regression\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      " R²: 0.742\n",
      " MAE: 4,208.23\n",
      " MSE: 37,277,681.70\n",
      " RMSE: 6,105.55\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.784\n",
      "MAE: 4,181.19\n",
      "MSE: 33,596,915.85\n",
      "RMSE: 5,796.28\n",
      "\u001b[4m\n",
      "Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.998\n",
      "MAE: 29.57\n",
      "MSE: 244,239.55\n",
      "RMSE: 494.21\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.707\n",
      "MAE: 3,173.69\n",
      "MSE: 45,555,188.39\n",
      "RMSE: 6,749.46\n",
      "\u001b[4m\n",
      "Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.975\n",
      "MAE: 1,069.70\n",
      "MSE: 3,659,206.68\n",
      "RMSE: 1,912.91\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.861\n",
      "MAE: 2,640.44\n",
      "MSE: 21,546,208.04\n",
      "RMSE: 4,641.79\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    r2 = r2_score(y, preds)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    return r2, mae, mse, rmse\n",
    "\n",
    "# Linear Regression ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nLinear Regression\" + \"\\x1B[0m\") \n",
    "r2_lr_tr, mae_lr_tr, mse_lr_tr, rmse_lr_tr = evaluate(LR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\" R²: {r2_lr_tr:.3f}\") \n",
    "print(f\" MAE: {mae_lr_tr:,.2f}\") \n",
    "print(f\" MSE: {mse_lr_tr:,.2f}\") \n",
    "print(f\" RMSE: {rmse_lr_tr:,.2f}\")\n",
    "\n",
    "r2_lr, mae_lr, mse_lr, rmse_lr = evaluate(LR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_lr:.3f}\") \n",
    "print(f\"MAE: {mae_lr:,.2f}\") \n",
    "print(f\"MSE: {mse_lr:,.2f}\")\n",
    "print(f\"RMSE: {rmse_lr:,.2f}\")\n",
    "    \n",
    "# Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nDecision Tree\" + \"\\x1B[0m\") \n",
    "r2_dt_tr, mae_dt_tr, mse_dt_tr, rmse_dt_tr = evaluate(DTR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_dt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_dt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt_tr:,.2f}\")\n",
    "\n",
    "r2_dt, mae_dt, mse_dt, rmse_dt = evaluate(DTR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt:.3f}\") \n",
    "print(f\"MAE: {mae_dt:,.2f}\") \n",
    "print(f\"MSE: {mse_dt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt:,.2f}\")\n",
    "\n",
    "# Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nRandom Forest\" + \"\\x1B[0m\") \n",
    "r2_rf_tr, mae_rf_tr, mse_rf_tr, rmse_rf_tr = evaluate(RF, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_rf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_rf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_rf_tr:,.2f}\")\n",
    "\n",
    "r2_rf, mae_rf, mse_rf, rmse_rf = evaluate(RF, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf:.3f}\") \n",
    "print(f\"MAE: {mae_rf:,.2f}\") \n",
    "print(f\"MSE: {mse_rf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_rf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b0172d",
   "metadata": {
    "papermill": {
     "duration": 0.005783,
     "end_time": "2025-12-24T20:18:48.863811",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.858028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.41 Optimization**\n",
    "---\n",
    "With evaluation metrics, lower values are better for MAE, MSE, and RMSE. As for the R² score, it should be higher. Out of the models evaluated so far, Random Forest had the best performance out of the box, with the Decision Tree model performing the least. The Decision Tree and Random Forest models will be optimized as they can be tuned with hyperparameters. The Bayesian Optimization library is used after installing it through the console. Bayesian Optimization was used over Grid Search and Random Search to effectively find the optimal hyperparameters for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e8866",
   "metadata": {
    "papermill": {
     "duration": 0.005575,
     "end_time": "2025-12-24T20:18:48.875012",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.869437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41a Decision Tree Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85a0ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:48.887657Z",
     "iopub.status.busy": "2025-12-24T20:18:48.887299Z",
     "iopub.status.idle": "2025-12-24T20:18:54.835123Z",
     "shell.execute_reply": "2025-12-24T20:18:54.834367Z"
    },
    "papermill": {
     "duration": 5.956546,
     "end_time": "2025-12-24T20:18:54.837267",
     "exception": false,
     "start_time": "2025-12-24T20:18:48.880721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.46e+07\u001b[39m | \u001b[39m8.1162622\u001b[39m | \u001b[39m19.112857\u001b[39m | \u001b[39m14.907884\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-3.28e+07\u001b[39m | \u001b[39m12.374511\u001b[39m | \u001b[39m4.8083355\u001b[39m | \u001b[39m3.9638958\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.57e+07\u001b[39m | \u001b[39m2.1035886\u001b[39m | \u001b[39m17.591170\u001b[39m | \u001b[39m12.421185\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.42e+07\u001b[39m | \u001b[35m14.453378\u001b[39m | \u001b[35m2.3705208\u001b[39m | \u001b[35m19.428287\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.96e+07\u001b[39m | \u001b[39m16.816410\u001b[39m | \u001b[39m5.8221039\u001b[39m | \u001b[39m4.4546743\u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-2.39e+07\u001b[39m | \u001b[35m11.385296\u001b[39m | \u001b[35m10.542765\u001b[39m | \u001b[35m20.0     \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m14.138448\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.55e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m9.9460183\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.42e+07\u001b[39m | \u001b[39m11.982222\u001b[39m | \u001b[39m8.9658312\u001b[39m | \u001b[39m19.883575\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m5.4251767\u001b[39m | \u001b[39m14.584147\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.49e+07\u001b[39m | \u001b[39m13.464222\u001b[39m | \u001b[39m13.229258\u001b[39m | \u001b[39m12.135924\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.41e+07\u001b[39m | \u001b[39m15.859325\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m18.526555\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.92e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m16.698567\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.54e+07\u001b[39m | \u001b[39m11.673448\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m8.5865338\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m-2.33e+07\u001b[39m | \u001b[35m5.8154771\u001b[39m | \u001b[35m12.320651\u001b[39m | \u001b[35m10.940210\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-4.40e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.48e+07\u001b[39m | \u001b[39m14.332692\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m11.971412\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.62e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m12.101485\u001b[39m | \u001b[39m8.5965694\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m18.205336\u001b[39m | \u001b[39m8.1242594\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.0300918\u001b[39m | \u001b[39m16.728894\u001b[39m | \u001b[39m10.570303\u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m11.323618\u001b[39m | \u001b[39m7.4461229\u001b[39m | \u001b[39m13.089682\u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.5918264\u001b[39m | \u001b[39m13.326961\u001b[39m | \u001b[39m15.063144\u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m14.245678\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m13.294957\u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m14.769305\u001b[39m | \u001b[39m14.560632\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 10}\n",
      "Best Score (Bayesian Optimization): -23326594.469013788\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from GeeksforGeeks, using bayesian optimization (https://www.geeksforgeeks.org/machine-learning/how-to-tune-a-decision-tree-in-hyperparameter-tuning/)\n",
    "def dt_mic(max_depth, min_samples_split, min_samples_leaf):\n",
    "    estimator = DecisionTreeRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5) # Minimizing MSE is equivalent to maximizing negative-MSE\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20)\n",
    "}\n",
    "\n",
    "dt_optimizer = BayesianOptimization(\n",
    "    f=dt_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt_optimizer.maximize(n_iter=25, init_points=5)\n",
    "best_params_dt = dt_optimizer.max['params']\n",
    "best_params_dt['max_depth'] = int(best_params_dt['max_depth'])\n",
    "best_params_dt['min_samples_split'] = int(best_params_dt['min_samples_split'])\n",
    "best_params_dt['min_samples_leaf'] = int(best_params_dt['min_samples_leaf'])\n",
    "best_score_dt = dt_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_dt}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bc5c7",
   "metadata": {
    "papermill": {
     "duration": 0.027222,
     "end_time": "2025-12-24T20:18:54.876269",
     "exception": false,
     "start_time": "2025-12-24T20:18:54.849047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ab75de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:54.904321Z",
     "iopub.status.busy": "2025-12-24T20:18:54.903941Z",
     "iopub.status.idle": "2025-12-24T20:18:54.920062Z",
     "shell.execute_reply": "2025-12-24T20:18:54.918596Z"
    },
    "papermill": {
     "duration": 0.033407,
     "end_time": "2025-12-24T20:18:54.922680",
     "exception": false,
     "start_time": "2025-12-24T20:18:54.889273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.867\n",
      "Optimized RMSE: 4,829.76\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Decision Tree Regressor\n",
    "DT_Bayes = DecisionTreeRegressor( \n",
    "    max_depth=best_params_dt['max_depth'], \n",
    "    min_samples_split=best_params_dt['min_samples_split'], \n",
    "    min_samples_leaf=best_params_dt['min_samples_leaf'], \n",
    "    random_state=42)\n",
    "\n",
    "DT_Bayes.fit(train_X, train_y)\n",
    "\n",
    "dt_mse_translate = -best_score_dt # Since the cross val score uses negative scoring, this turns it into a positive value\n",
    "dt_rmse_translate = np.sqrt(dt_mse_translate) # Square root of mse is rmse and is closer to the values used for medical insurance cost in $USD\n",
    "dt_preds = DT_Bayes.predict(val_X)\n",
    "dt_r2 = r2_score(val_y, dt_preds) \n",
    "\n",
    "print(f\"Optimized R²: {dt_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {dt_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed0236",
   "metadata": {
    "papermill": {
     "duration": 0.007072,
     "end_time": "2025-12-24T20:18:54.937361",
     "exception": false,
     "start_time": "2025-12-24T20:18:54.930289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41b Random Forest Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e4a53c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:18:54.954186Z",
     "iopub.status.busy": "2025-12-24T20:18:54.953880Z",
     "iopub.status.idle": "2025-12-24T20:21:02.795461Z",
     "shell.execute_reply": "2025-12-24T20:21:02.794268Z"
    },
    "papermill": {
     "duration": 127.852021,
     "end_time": "2025-12-24T20:21:02.797268",
     "exception": false,
     "start_time": "2025-12-24T20:18:54.945247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_esti... | max_depth | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.36e+07\u001b[39m | \u001b[39m249.81604\u001b[39m | \u001b[39m29.014286\u001b[39m | \u001b[39m7.8559515\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m339.46339\u001b[39m | \u001b[39m13.120372\u001b[39m | \u001b[39m3.2479561\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.38e+07\u001b[39m | \u001b[39m123.23344\u001b[39m | \u001b[39m27.323522\u001b[39m | \u001b[39m6.8089200\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.32e+07\u001b[39m | \u001b[35m383.22903\u001b[39m | \u001b[35m10.411689\u001b[39m | \u001b[35m9.7592788\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m432.97705\u001b[39m | \u001b[39m14.246782\u001b[39m | \u001b[39m3.4545997\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-2.34e+07\u001b[39m | \u001b[39m383.12355\u001b[39m | \u001b[39m10.428747\u001b[39m | \u001b[39m8.6841783\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m387.52410\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.50203\u001b[39m | \u001b[39m16.670786\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m396.41384\u001b[39m | \u001b[39m14.198882\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m395.99091\u001b[39m | \u001b[39m25.168777\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m403.23208\u001b[39m | \u001b[39m21.595070\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.63557\u001b[39m | \u001b[39m27.715969\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m375.82364\u001b[39m | \u001b[39m25.009127\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.24790\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.88791\u001b[39m | \u001b[39m18.238178\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m367.98182\u001b[39m | \u001b[39m24.949440\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m382.25633\u001b[39m | \u001b[39m22.129411\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m369.21462\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m359.87025\u001b[39m | \u001b[39m10.365589\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m354.88643\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m355.82650\u001b[39m | \u001b[39m19.782845\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.37e+07\u001b[39m | \u001b[39m189.70758\u001b[39m | \u001b[39m10.207937\u001b[39m | \u001b[39m6.6337112\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.40e+07\u001b[39m | \u001b[39m499.62040\u001b[39m | \u001b[39m29.559066\u001b[39m | \u001b[39m5.2809506\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m287.73411\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m289.65078\u001b[39m | \u001b[39m15.960336\u001b[39m | \u001b[39m2.0068777\u001b[39m |\n",
      "| \u001b[35m26       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m278.84161\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[35m27       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m268.81017\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m271.92727\u001b[39m | \u001b[39m18.680327\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m266.62652\u001b[39m | \u001b[39m15.173725\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m374.99721\u001b[39m | \u001b[39m16.319748\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'n_estimators': 268, 'max_depth': 10, 'min_samples_split': 10}\n",
      "Best Score (Bayesian Optimization): -23110676.701853152\n"
     ]
    }
   ],
   "source": [
    "def rf_mic(n_estimators, max_depth, min_samples_split):\n",
    "    estimator = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        random_state=42\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 30),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "rf_optimizer = BayesianOptimization(\n",
    "    f=rf_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "best_params_rf = rf_optimizer.max['params']\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['min_samples_split'] = int(best_params_rf['min_samples_split'])\n",
    "best_score_rf = rf_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_rf}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae68836",
   "metadata": {
    "papermill": {
     "duration": 0.008728,
     "end_time": "2025-12-24T20:21:02.814469",
     "exception": false,
     "start_time": "2025-12-24T20:21:02.805741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6f33e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:21:02.833347Z",
     "iopub.status.busy": "2025-12-24T20:21:02.832873Z",
     "iopub.status.idle": "2025-12-24T20:21:03.517631Z",
     "shell.execute_reply": "2025-12-24T20:21:03.516434Z"
    },
    "papermill": {
     "duration": 0.696132,
     "end_time": "2025-12-24T20:21:03.519133",
     "exception": false,
     "start_time": "2025-12-24T20:21:02.823001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.872\n",
      "Optimized RMSE: 4,807.36\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Random Forest Regressor\n",
    "RF_Bayes = RandomForestRegressor( \n",
    "    n_estimators=best_params_rf['n_estimators'], \n",
    "    max_depth=best_params_rf['max_depth'], \n",
    "    min_samples_split=best_params_rf['min_samples_split'], \n",
    "    random_state=42)\n",
    "\n",
    "RF_Bayes.fit(train_X, train_y)\n",
    "\n",
    "rf_mse_translate = -best_score_rf\n",
    "rf_rmse_translate = np.sqrt(rf_mse_translate)\n",
    "rf_preds = RF_Bayes.predict(val_X)\n",
    "rf_r2 = r2_score(val_y, rf_preds) \n",
    "\n",
    "print(f\"Optimized R²: {rf_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {rf_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91fdde",
   "metadata": {
    "papermill": {
     "duration": 0.00825,
     "end_time": "2025-12-24T20:21:03.536085",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.527835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Optimized Models Performance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1593f404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:21:03.554716Z",
     "iopub.status.busy": "2025-12-24T20:21:03.554232Z",
     "iopub.status.idle": "2025-12-24T20:21:03.645032Z",
     "shell.execute_reply": "2025-12-24T20:21:03.642603Z"
    },
    "papermill": {
     "duration": 0.103718,
     "end_time": "2025-12-24T20:21:03.648372",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.544654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Optimized Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.873\n",
      "MAE: 2,420.59\n",
      "MSE: 18,311,904.31\n",
      "RMSE: 4,279.24\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.867\n",
      "MAE: 2,646.49\n",
      "MSE: 20,594,594.98\n",
      "RMSE: 4,538.13\n",
      "\u001b[4m\n",
      "Optimized Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.924\n",
      "MAE: 1,842.33\n",
      "MSE: 10,936,379.26\n",
      "RMSE: 3,307.02\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.872\n",
      "MAE: 2,542.78\n",
      "MSE: 19,878,928.21\n",
      "RMSE: 4,458.58\n"
     ]
    }
   ],
   "source": [
    "# Optimized Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Decision Tree\" + \"\\x1B[0m\") \n",
    "r2_odt_tr, mae_odt_tr, mse_odt_tr, rmse_odt_tr = evaluate(DT_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_odt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_odt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt_tr:,.2f}\")\n",
    "\n",
    "r2_odt, mae_odt, mse_odt, rmse_odt = evaluate(DT_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt:.3f}\") \n",
    "print(f\"MAE: {mae_odt:,.2f}\") \n",
    "print(f\"MSE: {mse_odt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt:,.2f}\")\n",
    "\n",
    "# Optimized Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Random Forest\" + \"\\x1B[0m\") \n",
    "r2_orf_tr, mae_orf_tr, mse_orf_tr, rmse_orf_tr = evaluate(RF_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_orf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_orf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_orf_tr:,.2f}\")\n",
    "\n",
    "r2_orf, mae_orf, mse_orf, rmse_orf = evaluate(RF_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf:.3f}\") \n",
    "print(f\"MAE: {mae_orf:,.2f}\") \n",
    "print(f\"MSE: {mse_orf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_orf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c086f",
   "metadata": {
    "papermill": {
     "duration": 0.009503,
     "end_time": "2025-12-24T20:21:03.675522",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.666019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.5 Functions for Gradio**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a745872",
   "metadata": {
    "papermill": {
     "duration": 0.008611,
     "end_time": "2025-12-24T20:21:03.693051",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.684440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.51 Function 1**\n",
    "---\n",
    "Since the user will have to input categorical features alongside numerical inputs, they will have to be formatted accordingly. In this function, a copy of the original dataset is made, and the features are filled in correspondingly. Since age, bmi, and children are numerical features, they already work fine with the function. However, sex, smoker, and region are categorical features, which means they have to be numerical for the function to work. The problem is bypassed by checking if the user input matches the previously one-hot encoded categorical features, like sex, which is turned into sex_female or sex_male by pandas. Now that the features are numerical, they can be used in the function for model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4489835e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:21:03.712790Z",
     "iopub.status.busy": "2025-12-24T20:21:03.712338Z",
     "iopub.status.idle": "2025-12-24T20:21:03.718823Z",
     "shell.execute_reply": "2025-12-24T20:21:03.717608Z"
    },
    "papermill": {
     "duration": 0.01825,
     "end_time": "2025-12-24T20:21:03.720520",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.702270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_input(age, sex, bmi, children, smoker, region):\n",
    "    input_row = pd.DataFrame(0, index=[0], columns=X.columns)\n",
    "\n",
    "    input_row['age'] = age\n",
    "    input_row['bmi'] = bmi\n",
    "    input_row['children'] = children\n",
    "\n",
    "    # one-hot categorical\n",
    "    col = f\"sex_{sex}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"smoker_{smoker}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"region_{region}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    return input_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc940f",
   "metadata": {
    "papermill": {
     "duration": 0.008416,
     "end_time": "2025-12-24T20:21:03.737788",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.729372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.52 Function 2**\n",
    "---\n",
    "This section contains the prediction function that Gradio will use. In the function, the categorical features are turned into lowercase versions to match the dataset columns. The previous function is then called, which lets the rest of the function work as explained earlier. The rest of the code is now just an if-else statement checking what model the user has chosen, wherein it will then use sklearn's predict method using the built inputs with the type of model it is for. The predictions are the target feature in the dataset, which is \"charges\", or the Medical Insurance Cost that the tool is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd07a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:21:03.756497Z",
     "iopub.status.busy": "2025-12-24T20:21:03.756212Z",
     "iopub.status.idle": "2025-12-24T20:21:03.763343Z",
     "shell.execute_reply": "2025-12-24T20:21:03.762213Z"
    },
    "papermill": {
     "duration": 0.018884,
     "end_time": "2025-12-24T20:21:03.764891",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.746007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, age, sex, bmi, children, smoker, region):\n",
    "    # Dataset columns are lowercase, but user input first letters are uppercased for formatting aesthetics\n",
    "    sex = sex.lower()\n",
    "    smoker = smoker.lower()\n",
    "    region = region.lower()\n",
    "\n",
    "    input_df = build_input(age, sex, bmi, children, smoker, region)\n",
    "    \n",
    "    if model == 'Linear Regression':\n",
    "        preds = LR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Decision Tree':\n",
    "        preds = DTR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Random Forest':\n",
    "        preds = RF.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized DT':\n",
    "        preds = DT_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized RF':\n",
    "        preds = RF_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216eb6e",
   "metadata": {
    "papermill": {
     "duration": 0.008502,
     "end_time": "2025-12-24T20:21:03.781998",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.773496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.6 Gradio Interface**\n",
    "---\n",
    "To use the functions through a GUI, Gradio will be used as it provides a clean interface for deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1072f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T20:21:03.801047Z",
     "iopub.status.busy": "2025-12-24T20:21:03.800588Z",
     "iopub.status.idle": "2025-12-24T20:21:05.774396Z",
     "shell.execute_reply": "2025-12-24T20:21:05.773313Z"
    },
    "papermill": {
     "duration": 1.985449,
     "end_time": "2025-12-24T20:21:05.776056",
     "exception": false,
     "start_time": "2025-12-24T20:21:03.790607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://52ef6eee738e930688.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://52ef6eee738e930688.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    gr.Dropdown([\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Optimized DT\", \"Optimized RF\"], value=\"Optimized RF\", label=\"Model\"),\n",
    "    gr.Number(label=\"Age\", minimum=0),\n",
    "    gr.Dropdown([\"Male\", \"Female\"], label=\"Sex\"),\n",
    "    gr.Number(label=\"BMI\"),\n",
    "    gr.Number(label=\"Number of children\"),\n",
    "    gr.Dropdown([\"No\", \"Yes\"], label=\"Smoker\"),\n",
    "    gr.Dropdown([\"Northeast\", \"Northwest\", \"Southeast\", \"Southwest\"], label=\"Location\")\n",
    "]\n",
    "\n",
    "outputs = gr.Textbox(label=\"Predicted Charge\")\n",
    "\n",
    "css = \"\"\"\n",
    ".gradio-container{\n",
    "margin-top: 3rem !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "PredictiveTool = gr.Interface(\n",
    "    fn=predict, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    title=\"Medical Insurance Cost\",\n",
    "    theme=gr.themes.Soft(), # Different theme to change the look of the tool. The blue, monochromatic palette goes well with how medical/healthcare designs are generally represented.\n",
    "    css=css\n",
    ")\n",
    "PredictiveTool.launch(height=900) # Bigger Rendered HTML height for UX design so users do not have to scroll to use the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbdabe",
   "metadata": {
    "papermill": {
     "duration": 0.009598,
     "end_time": "2025-12-24T20:21:05.795004",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.785406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Deliverables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6acdad5",
   "metadata": {
    "papermill": {
     "duration": 0.016128,
     "end_time": "2025-12-24T20:21:05.824837",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.808709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.1 Dataset Description**\n",
    "The dataset this ML problem is trained on is from the Medical Insurance Cost Dataset by Mosap Abdel-Ghany here on Kaggle (https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset). \n",
    "\n",
    "The dataset contains 1338 rows and 7 columns, with 4 numerical features and 3 categorical features. The dataset has already been cleaned beforehand so there are no invalid data. The numerical features are: age, bmi, children, and charges. The categorical features are: sex, smoker, and region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124c3a6",
   "metadata": {
    "papermill": {
     "duration": 0.008809,
     "end_time": "2025-12-24T20:21:05.846678",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.837869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.2 Preprocessing**\n",
    "#### 2.2a One-hot encoding\n",
    "The 3 categorical features, sex, smoker, and region have to undergo Pandas’ pd.getdummies() method, which will turn them into numerical features.\n",
    "\n",
    "#### 2.2b Splitting data\n",
    "The train_test_split() method from sklearn is used to obtain the values for train_X, val_X, train_y, and val_y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe8998",
   "metadata": {
    "papermill": {
     "duration": 0.009464,
     "end_time": "2025-12-24T20:21:05.864700",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.855236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.3 Model Implementation**\n",
    "#### 2.3a Fitting Models\n",
    "Sklearn’s model.fit() method was used alongside the split data, wherein three different variables, each representing different models such as LR for Linear Regression, DTR for Decision Tree Regressor, and RF for Random Forest.\n",
    "\n",
    "#### 2.3b Checking Model Performance\n",
    "An evaluate function was made containing the model.predict(), r2_score(), mean_absolute_error(), mean_squared_error(), np.sqrt(mean_squared_error()) methods, which were returned to use as arguments for evaluating training and validation data. The training and validation scores were separated for later interpretation.\n",
    "\n",
    "#### 2.3c Optimizing Models\n",
    "The Bayesian Optimization library was used for effectively finding the optimal hyperparameters for the Optimized Decision Tree and Random Forest models after installing it from the console. Afterwards, the maximize() method’s results from the library were used as hyperparameters for the Decision Tree and Random Forest models’ new variables.\n",
    "\n",
    "#### 2.3d Checking Optimized Model Performance\n",
    "The evaluate function earlier was called on the new variables, and the code was adapted accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b6759e",
   "metadata": {
    "papermill": {
     "duration": 0.008735,
     "end_time": "2025-12-24T20:21:05.881911",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.873176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.4 Results**\n",
    "The results are as follows:\n",
    "\n",
    "#### <u>Linear Regression</u>\n",
    "\n",
    "**Train:**\n",
    "\n",
    "R²: 0.742\n",
    "\n",
    "MAE: 4,208.23\n",
    "\n",
    "MSE: 37,277,681.70\n",
    "\n",
    "RMSE: 6,105.55\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "R²: 0.784\n",
    "\n",
    "MAE: 4,181.19\n",
    "\n",
    "MSE: 33,596,915.85\n",
    "\n",
    "RMSE: 5,796.28\n",
    "\n",
    "#### <u>Decision Tree</u>\n",
    "\n",
    "**Train:**\n",
    "\n",
    "R²: 0.998\n",
    "\n",
    "MAE: 29.57\n",
    "\n",
    "MSE: 244,239.55\n",
    "\n",
    "RMSE: 494.21\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "R²: 0.721\n",
    "\n",
    "MAE: 3,206.26\n",
    "\n",
    "MSE: 43,246,514.96\n",
    "\n",
    "RMSE: 6,576.21\n",
    "\n",
    "#### <u>Random Forest</u>\n",
    "\n",
    "**Train:**\n",
    "\n",
    "R²: 0.974\n",
    "\n",
    "MAE: 1,067.49\n",
    "\n",
    "MSE: 3,701,163.95\n",
    "\n",
    "RMSE: 1,923.84\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "R²: 0.861\n",
    "\n",
    "MAE: 2,578.30\n",
    "\n",
    "MSE: 21,567,207.59\n",
    "\n",
    "RMSE: 4,644.05\n",
    "\n",
    "#### <u>Optimized Decision Tree</u>\n",
    "\n",
    "**Train:**\n",
    "\n",
    "R²: 0.873\n",
    "\n",
    "MAE: 2,420.59\n",
    "\n",
    "MSE: 18,311,904.31\n",
    "\n",
    "RMSE: 4,279.24\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "R²: 0.867\n",
    "\n",
    "MAE: 2,646.49\n",
    "\n",
    "MSE: 20,594,594.98\n",
    "\n",
    "RMSE: 4,538.13\n",
    "\n",
    "#### <u>Optimized Random Forest</u>\n",
    "\n",
    "**Train:**\n",
    "\n",
    "R²: 0.924\n",
    "\n",
    "MAE: 1,842.33\n",
    "\n",
    "MSE: 10,936,379.26\n",
    "\n",
    "RMSE: 3,307.02\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "R²: 0.872\n",
    "\n",
    "MAE: 2,542.78\n",
    "\n",
    "MSE: 19,878,928.21\n",
    "\n",
    "RMSE: 4,458.58\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94a240",
   "metadata": {
    "papermill": {
     "duration": 0.008584,
     "end_time": "2025-12-24T20:21:05.899418",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.890834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.5 Interpretation**\n",
    "Since the training and validation scores are provided, interpreting the performances of each model can now be done properly. Their performances will be checked using their **R²**, **MAE**, and **RMSE**. With **R²**, higher values are better, as it means the model captures the trends accurately. **MAE** is regarding the average of the absolute differences between the predicted and actual charges, which still applies to the train and validation sets. **RMSE** is similar to **MAE**, but penalizes large errors more; lower is better for both **MAE** and **RMSE**.\n",
    "\n",
    "#### 2.5a Linear Regression\n",
    "The gap between the train and validation's R² scores is 0.042, which is not that much and means it is slightly overfitting. It is not underfitting as well since the values are high and not something like 0.5. Overall, the validation metrics are slightly better than the training metrics. The close difference between the two metrics means that the model behaves consistently on seen and unseen data, and generalizes decently.\n",
    "\n",
    "#### 2.5b Decision Tree\n",
    "The gap between the train and validation's R² scores is 0.277, which is a lot and means that the model is severely overfitting. The MAE, MSE, and RMSE scores for the training set are incredibly low, with the R² score being close to 1. It means the Decision Tree model basically memorized the training data in its entirety, but that means it won't perform as well on unseen data. Overall, the massive discrepancy between the training and validation sets shows that the model is inconsistent and cannot generalize reliably.\n",
    "\n",
    "#### 2.5c Random Forest\n",
    "The gap between the train and validation R² scores is 0.113, which means that the model is moderately overfitting. The R², MAE, MSE, and RMSE metrics on the train set being incredibly good means that the Random Forest model properly memorized the training data. The validation metrics show good scores, which means that the model explains unseen data decently. Overall, the difference between the two metrics only shows that the model is moderately overfitting, but it is not alarming enough to brand the model as unreliable since it generalizes pretty well.\n",
    "\n",
    "#### 2.5d Optimized Decision Tree\n",
    "The gap between the train and validation R² scores is 0.006, which is incredibly good. The difference between the train and validation metrics being very close means that the model is very stable. It generalizes unseen data well, which balances the training accuracy with reliable real-world performance. Overall, it means that the model is good and reliable enough to be used as a medical insurance cost predictor.\n",
    "\n",
    "#### 2.5e Optimized Random Forest\n",
    "The gap between the train and validation R² scores is 0.052, which means that it is slightly overfitting. The difference between the train and validation metrics is technically larger compared to the Optimized Decision Tree's results, but it ends up being slightly better in a real-world scenario due to the validation metrics being a step above the Optimized Decision Tree's. Overall, it is a good pick to use as a predictor model for the medical insurance cost regression problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6be77",
   "metadata": {
    "papermill": {
     "duration": 0.008812,
     "end_time": "2025-12-24T20:21:05.916707",
     "exception": false,
     "start_time": "2025-12-24T20:21:05.907895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.6 Critical Reflection**\n",
    "\n",
    "Creating this Medical Insurance Cost prediction tool was a rather surprising experience compared to my attempt at doing a time-based split regression task, which was used in my assessment a few months ago. In this assessment, I was able to create a Medical Insurance Cost prediction tool with 3 models and 2 optimized variants, wherein a Gradio interface was provided to provide an area wherein users could input the provided features, which is very helpful in scenarios where it can be shared online, as anyone can use it without having to understand code. I say that it is surprising because I found myself trying to make a regression task interesting, since classification tasks like face-tracking seem more impressive than regression tasks. Impressions aside, they do solve different problems, which means that neither is “better” than the other. Compared to my previous regression task, this assessment output provides a tool that can be used by the public to find predictions that they don't just brush away like they would in the other task.\n",
    "\n",
    "While I could have just settled with three models and built the Gradio interface with those, I felt that it was too lacking for a regression task, and especially for something that targets a real-world problem like this. I had to know whether the models were performing reliably enough that they could be used to prepare someone with their funding rather than lowball or highball their estimates. That meant I had to optimize the models by tuning the hyperparameters. To get them, my options were to use Random Search, Grid Search, and Bayesian Optimization. I decided on Bayesian Optimization because it was the most efficient and fastest method to get the best hyperparameters to use for the optimized models. Those hyperparameters were then used on the Decision Tree and Random Forest models. All the models had to be evaluated as well to see their performances and see if the optimization process worked out well, which is why the training and validation data sets were evaluated to find the gaps between their metrics to see if the models were fitted correctly.\n",
    "\n",
    "I think I was able to work on the Machine Learning regression problem decently, although there are some gaps that I cannot currently recognize just plainly due to having early experience and knowledge. Working on this regression task, especially with Gradio, has opened up venues of interest for me to further test my curiosity with Machine Learning and AI that I may end up following through even after this module is over."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8129551,
     "sourceId": 12853160,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.430029,
   "end_time": "2025-12-24T20:21:08.547010",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T20:18:32.116981",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
