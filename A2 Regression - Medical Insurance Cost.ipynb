{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8452885e",
   "metadata": {
    "papermill": {
     "duration": 0.006411,
     "end_time": "2025-12-24T13:49:27.384412",
     "exception": false,
     "start_time": "2025-12-24T13:49:27.378001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **<span style=\"color: green;\">Predictive Regression Tool Using Gradio</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae614b",
   "metadata": {
    "papermill": {
     "duration": 0.005311,
     "end_time": "2025-12-24T13:49:27.395491",
     "exception": false,
     "start_time": "2025-12-24T13:49:27.390180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![](https://i.imgur.com/spUaGoh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a0bfef",
   "metadata": {
    "papermill": {
     "duration": 0.00534,
     "end_time": "2025-12-24T13:49:27.406885",
     "exception": false,
     "start_time": "2025-12-24T13:49:27.401545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Medical Insurance Cost**\n",
    "---\n",
    "![](https://storage.googleapis.com/kaggle-datasets-images/8129551/12853160/83b336ea7f928c215b00bfb0681810f1/dataset-cover.jpg?t=2025-08-24-12-28-03)\n",
    "\n",
    "*(https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)*\n",
    "\n",
    "\n",
    "For Assessment 2, we are required to solve a Machine Learning problem of any type. For this project, I decided to work with a Regression Task. We were also instructed to use Gradio to work with the Machine Learning Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d72329",
   "metadata": {
    "papermill": {
     "duration": 0.005248,
     "end_time": "2025-12-24T13:49:27.417573",
     "exception": false,
     "start_time": "2025-12-24T13:49:27.412325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.1 Importing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6aee5d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:27.430316Z",
     "iopub.status.busy": "2025-12-24T13:49:27.429964Z",
     "iopub.status.idle": "2025-12-24T13:49:37.721902Z",
     "shell.execute_reply": "2025-12-24T13:49:37.720830Z"
    },
    "papermill": {
     "duration": 10.300232,
     "end_time": "2025-12-24T13:49:37.723637",
     "exception": false,
     "start_time": "2025-12-24T13:49:27.423405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c89024",
   "metadata": {
    "papermill": {
     "duration": 0.005211,
     "end_time": "2025-12-24T13:49:37.734521",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.729310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.2 Printing CSV and Data Checking**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e98014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:37.746938Z",
     "iopub.status.busy": "2025-12-24T13:49:37.745975Z",
     "iopub.status.idle": "2025-12-24T13:49:37.804712Z",
     "shell.execute_reply": "2025-12-24T13:49:37.803697Z"
    },
    "papermill": {
     "duration": 0.066944,
     "end_time": "2025-12-24T13:49:37.806580",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.739636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n",
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic = pd.read_csv('/kaggle/input/medical-insurance-cost-dataset/insurance.csv')\n",
    "print(mic.shape)\n",
    "print(mic.columns)\n",
    "mic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474615e",
   "metadata": {
    "papermill": {
     "duration": 0.005701,
     "end_time": "2025-12-24T13:49:37.818187",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.812486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 1338 rows, and seven columns with the categories: age, sex, bmi, children, smoker, region, and charges. Since ML trains on numerical data, the categorical features will have to be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d1f2d",
   "metadata": {
    "papermill": {
     "duration": 0.005998,
     "end_time": "2025-12-24T13:49:37.829713",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.823715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.21 Cleaning Data**\n",
    "---\n",
    "It is still good to check if any cells have missing or unsupported data. The isna().sum() functions from pandas are used together to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad43fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:37.842636Z",
     "iopub.status.busy": "2025-12-24T13:49:37.842268Z",
     "iopub.status.idle": "2025-12-24T13:49:37.851157Z",
     "shell.execute_reply": "2025-12-24T13:49:37.850243Z"
    },
    "papermill": {
     "duration": 0.017729,
     "end_time": "2025-12-24T13:49:37.852897",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.835168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5072d",
   "metadata": {
    "papermill": {
     "duration": 0.005423,
     "end_time": "2025-12-24T13:49:37.864277",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.858854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.3 Regression Task**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faac3771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:37.877127Z",
     "iopub.status.busy": "2025-12-24T13:49:37.876781Z",
     "iopub.status.idle": "2025-12-24T13:49:38.287814Z",
     "shell.execute_reply": "2025-12-24T13:49:38.286834Z"
    },
    "papermill": {
     "duration": 0.419998,
     "end_time": "2025-12-24T13:49:38.289850",
     "exception": false,
     "start_time": "2025-12-24T13:49:37.869852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mic.drop('charges', axis=1)\n",
    "X = pd.get_dummies(X, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "y = mic['charges']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "LR = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "DTR = DecisionTreeRegressor().fit(train_X, train_y)\n",
    "\n",
    "RF = RandomForestRegressor().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d650c",
   "metadata": {
    "papermill": {
     "duration": 0.005777,
     "end_time": "2025-12-24T13:49:38.301419",
     "exception": false,
     "start_time": "2025-12-24T13:49:38.295642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.4 Model Performance & Optimization**\n",
    "---\n",
    "The accuracy of the models have to be determined to see if the tool is reliable and ready to be deployed for people to use. The provided function works with sklearn's imported functions, evaluating the different models that were previously named. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42ada63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:38.314466Z",
     "iopub.status.busy": "2025-12-24T13:49:38.314149Z",
     "iopub.status.idle": "2025-12-24T13:49:38.371343Z",
     "shell.execute_reply": "2025-12-24T13:49:38.369980Z"
    },
    "papermill": {
     "duration": 0.066132,
     "end_time": "2025-12-24T13:49:38.373298",
     "exception": false,
     "start_time": "2025-12-24T13:49:38.307166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Linear Regression\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      " R²: 0.742\n",
      " MAE: 4,208.23\n",
      " MSE: 37,277,681.70\n",
      " RMSE: 6,105.55\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.784\n",
      "MAE: 4,181.19\n",
      "MSE: 33,596,915.85\n",
      "RMSE: 5,796.28\n",
      "\u001b[4m\n",
      "Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.998\n",
      "MAE: 29.57\n",
      "MSE: 244,239.55\n",
      "RMSE: 494.21\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.693\n",
      "MAE: 3,403.37\n",
      "MSE: 47,610,601.29\n",
      "RMSE: 6,900.04\n",
      "\u001b[4m\n",
      "Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.975\n",
      "MAE: 1,057.10\n",
      "MSE: 3,607,155.04\n",
      "RMSE: 1,899.25\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.862\n",
      "MAE: 2,555.58\n",
      "MSE: 21,378,265.59\n",
      "RMSE: 4,623.66\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    r2 = r2_score(y, preds)\n",
    "    mae = mean_absolute_error(y, preds)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "    return r2, mae, mse, rmse\n",
    "\n",
    "# Linear Regression ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nLinear Regression\" + \"\\x1B[0m\") \n",
    "r2_lr_tr, mae_lr_tr, mse_lr_tr, rmse_lr_tr = evaluate(LR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\" R²: {r2_lr_tr:.3f}\") \n",
    "print(f\" MAE: {mae_lr_tr:,.2f}\") \n",
    "print(f\" MSE: {mse_lr_tr:,.2f}\") \n",
    "print(f\" RMSE: {rmse_lr_tr:,.2f}\")\n",
    "\n",
    "r2_lr, mae_lr, mse_lr, rmse_lr = evaluate(LR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_lr:.3f}\") \n",
    "print(f\"MAE: {mae_lr:,.2f}\") \n",
    "print(f\"MSE: {mse_lr:,.2f}\")\n",
    "print(f\"RMSE: {rmse_lr:,.2f}\")\n",
    "    \n",
    "# Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nDecision Tree\" + \"\\x1B[0m\") \n",
    "r2_dt_tr, mae_dt_tr, mse_dt_tr, rmse_dt_tr = evaluate(DTR, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_dt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_dt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt_tr:,.2f}\")\n",
    "\n",
    "r2_dt, mae_dt, mse_dt, rmse_dt = evaluate(DTR, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_dt:.3f}\") \n",
    "print(f\"MAE: {mae_dt:,.2f}\") \n",
    "print(f\"MSE: {mse_dt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt:,.2f}\")\n",
    "\n",
    "# Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nRandom Forest\" + \"\\x1B[0m\") \n",
    "r2_rf_tr, mae_rf_tr, mse_rf_tr, rmse_rf_tr = evaluate(RF, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_rf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_rf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_rf_tr:,.2f}\")\n",
    "\n",
    "r2_rf, mae_rf, mse_rf, rmse_rf = evaluate(RF, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_rf:.3f}\") \n",
    "print(f\"MAE: {mae_rf:,.2f}\") \n",
    "print(f\"MSE: {mse_rf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_rf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1240ebb",
   "metadata": {
    "papermill": {
     "duration": 0.005912,
     "end_time": "2025-12-24T13:49:38.385305",
     "exception": false,
     "start_time": "2025-12-24T13:49:38.379393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.41 Optimization**\n",
    "---\n",
    "With evaluation metrics, lower values are better for MAE, MSE, and RMSE. As for the R² score, it should be higher. Out of the models evaluated so far, Random Forest had the best performance out of the box, with the Decision Tree model performing the least. The Decision Tree and Random Forest models will be optimized as they can be tuned with hyperparameters. The Bayesian Optimization library is used after installing it through the console. Bayesian Optimization was used over Grid Search and Random Search to effectively find the optimal hyperparameters for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1bc3c3",
   "metadata": {
    "papermill": {
     "duration": 0.006042,
     "end_time": "2025-12-24T13:49:38.396996",
     "exception": false,
     "start_time": "2025-12-24T13:49:38.390954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41a Decision Tree Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97b8fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:38.411233Z",
     "iopub.status.busy": "2025-12-24T13:49:38.410860Z",
     "iopub.status.idle": "2025-12-24T13:49:44.435129Z",
     "shell.execute_reply": "2025-12-24T13:49:44.434291Z"
    },
    "papermill": {
     "duration": 6.03436,
     "end_time": "2025-12-24T13:49:44.437184",
     "exception": false,
     "start_time": "2025-12-24T13:49:38.402824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.46e+07\u001b[39m | \u001b[39m8.1162622\u001b[39m | \u001b[39m19.112857\u001b[39m | \u001b[39m14.907884\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-3.28e+07\u001b[39m | \u001b[39m12.374511\u001b[39m | \u001b[39m4.8083355\u001b[39m | \u001b[39m3.9638958\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.57e+07\u001b[39m | \u001b[39m2.1035886\u001b[39m | \u001b[39m17.591170\u001b[39m | \u001b[39m12.421185\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.42e+07\u001b[39m | \u001b[35m14.453378\u001b[39m | \u001b[35m2.3705208\u001b[39m | \u001b[35m19.428287\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.96e+07\u001b[39m | \u001b[39m16.816410\u001b[39m | \u001b[39m5.8221039\u001b[39m | \u001b[39m4.4546743\u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-2.39e+07\u001b[39m | \u001b[35m11.385296\u001b[39m | \u001b[35m10.542765\u001b[39m | \u001b[35m20.0     \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m14.138448\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.55e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m9.9460183\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.42e+07\u001b[39m | \u001b[39m11.982222\u001b[39m | \u001b[39m8.9658312\u001b[39m | \u001b[39m19.883575\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m5.4251767\u001b[39m | \u001b[39m14.584147\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.49e+07\u001b[39m | \u001b[39m13.464222\u001b[39m | \u001b[39m13.229258\u001b[39m | \u001b[39m12.135924\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.41e+07\u001b[39m | \u001b[39m15.859325\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m18.526555\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.92e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m16.698567\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.54e+07\u001b[39m | \u001b[39m11.673448\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m8.5865338\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m-2.33e+07\u001b[39m | \u001b[35m5.8154771\u001b[39m | \u001b[35m12.320651\u001b[39m | \u001b[35m10.940210\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-4.40e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.48e+07\u001b[39m | \u001b[39m14.332692\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m11.971412\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.62e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m12.101485\u001b[39m | \u001b[39m8.5965694\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m18.205336\u001b[39m | \u001b[39m8.1242594\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.0300918\u001b[39m | \u001b[39m16.728894\u001b[39m | \u001b[39m10.570303\u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m11.323618\u001b[39m | \u001b[39m7.4461229\u001b[39m | \u001b[39m13.089682\u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.5918264\u001b[39m | \u001b[39m13.326961\u001b[39m | \u001b[39m15.063144\u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m14.245678\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m13.294957\u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m14.769305\u001b[39m | \u001b[39m14.560632\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 10}\n",
      "Best Score (Bayesian Optimization): -23326594.469013788\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from GeeksforGeeks, using bayesian optimization (https://www.geeksforgeeks.org/machine-learning/how-to-tune-a-decision-tree-in-hyperparameter-tuning/)\n",
    "def dt_mic(max_depth, min_samples_split, min_samples_leaf):\n",
    "    estimator = DecisionTreeRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5) # Minimizing MSE is equivalent to maximizing negative-MSE\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20)\n",
    "}\n",
    "\n",
    "dt_optimizer = BayesianOptimization(\n",
    "    f=dt_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt_optimizer.maximize(n_iter=25, init_points=5)\n",
    "best_params_dt = dt_optimizer.max['params']\n",
    "best_params_dt['max_depth'] = int(best_params_dt['max_depth'])\n",
    "best_params_dt['min_samples_split'] = int(best_params_dt['min_samples_split'])\n",
    "best_params_dt['min_samples_leaf'] = int(best_params_dt['min_samples_leaf'])\n",
    "best_score_dt = dt_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_dt}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc191bf",
   "metadata": {
    "papermill": {
     "duration": 0.012031,
     "end_time": "2025-12-24T13:49:44.460705",
     "exception": false,
     "start_time": "2025-12-24T13:49:44.448674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f69095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:44.485240Z",
     "iopub.status.busy": "2025-12-24T13:49:44.484870Z",
     "iopub.status.idle": "2025-12-24T13:49:44.504449Z",
     "shell.execute_reply": "2025-12-24T13:49:44.503661Z"
    },
    "papermill": {
     "duration": 0.034143,
     "end_time": "2025-12-24T13:49:44.506322",
     "exception": false,
     "start_time": "2025-12-24T13:49:44.472179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.867\n",
      "Optimized RMSE: 4,829.76\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Decision Tree Regressor\n",
    "DT_Bayes = DecisionTreeRegressor( \n",
    "    max_depth=best_params_dt['max_depth'], \n",
    "    min_samples_split=best_params_dt['min_samples_split'], \n",
    "    min_samples_leaf=best_params_dt['min_samples_leaf'], \n",
    "    random_state=42)\n",
    "\n",
    "DT_Bayes.fit(train_X, train_y)\n",
    "\n",
    "dt_mse_translate = -best_score_dt # Since the cross val score uses negative scoring, this turns it into a positive value\n",
    "dt_rmse_translate = np.sqrt(dt_mse_translate) # Square root of mse is rmse and is closer to the values used for medical insurance cost in $USD\n",
    "dt_preds = DT_Bayes.predict(val_X)\n",
    "dt_r2 = r2_score(val_y, dt_preds) \n",
    "\n",
    "print(f\"Optimized R²: {dt_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {dt_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153df5e3",
   "metadata": {
    "papermill": {
     "duration": 0.007481,
     "end_time": "2025-12-24T13:49:44.523633",
     "exception": false,
     "start_time": "2025-12-24T13:49:44.516152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41b Random Forest Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc22e300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:49:44.539219Z",
     "iopub.status.busy": "2025-12-24T13:49:44.538723Z",
     "iopub.status.idle": "2025-12-24T13:51:55.048874Z",
     "shell.execute_reply": "2025-12-24T13:51:55.047798Z"
    },
    "papermill": {
     "duration": 130.519598,
     "end_time": "2025-12-24T13:51:55.050529",
     "exception": false,
     "start_time": "2025-12-24T13:49:44.530931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_esti... | max_depth | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.36e+07\u001b[39m | \u001b[39m249.81604\u001b[39m | \u001b[39m29.014286\u001b[39m | \u001b[39m7.8559515\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m339.46339\u001b[39m | \u001b[39m13.120372\u001b[39m | \u001b[39m3.2479561\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.38e+07\u001b[39m | \u001b[39m123.23344\u001b[39m | \u001b[39m27.323522\u001b[39m | \u001b[39m6.8089200\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.32e+07\u001b[39m | \u001b[35m383.22903\u001b[39m | \u001b[35m10.411689\u001b[39m | \u001b[35m9.7592788\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m432.97705\u001b[39m | \u001b[39m14.246782\u001b[39m | \u001b[39m3.4545997\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-2.34e+07\u001b[39m | \u001b[39m383.12355\u001b[39m | \u001b[39m10.428747\u001b[39m | \u001b[39m8.6841783\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m387.52410\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.50203\u001b[39m | \u001b[39m16.670786\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m396.41384\u001b[39m | \u001b[39m14.198882\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m395.99091\u001b[39m | \u001b[39m25.168777\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m403.23208\u001b[39m | \u001b[39m21.595070\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.63557\u001b[39m | \u001b[39m27.715969\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m375.82364\u001b[39m | \u001b[39m25.009127\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.24790\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.88791\u001b[39m | \u001b[39m18.238178\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m367.98182\u001b[39m | \u001b[39m24.949440\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m382.25633\u001b[39m | \u001b[39m22.129411\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m369.21462\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m359.87025\u001b[39m | \u001b[39m10.365589\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m354.88643\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m355.82650\u001b[39m | \u001b[39m19.782845\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.37e+07\u001b[39m | \u001b[39m189.70758\u001b[39m | \u001b[39m10.207937\u001b[39m | \u001b[39m6.6337112\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.40e+07\u001b[39m | \u001b[39m499.62040\u001b[39m | \u001b[39m29.559066\u001b[39m | \u001b[39m5.2809506\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m287.73411\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m289.65078\u001b[39m | \u001b[39m15.960336\u001b[39m | \u001b[39m2.0068777\u001b[39m |\n",
      "| \u001b[35m26       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m278.84161\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[35m27       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m268.81017\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m271.92727\u001b[39m | \u001b[39m18.680327\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m266.62652\u001b[39m | \u001b[39m15.173725\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m374.99721\u001b[39m | \u001b[39m16.319748\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'n_estimators': 268, 'max_depth': 10, 'min_samples_split': 10}\n",
      "Best Score (Bayesian Optimization): -23110676.701853152\n"
     ]
    }
   ],
   "source": [
    "def rf_mic(n_estimators, max_depth, min_samples_split):\n",
    "    estimator = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        random_state=42\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 30),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "rf_optimizer = BayesianOptimization(\n",
    "    f=rf_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "best_params_rf = rf_optimizer.max['params']\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['min_samples_split'] = int(best_params_rf['min_samples_split'])\n",
    "best_score_rf = rf_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_rf}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8c6d0f",
   "metadata": {
    "papermill": {
     "duration": 0.00835,
     "end_time": "2025-12-24T13:51:55.067642",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.059292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d6e682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:51:55.086144Z",
     "iopub.status.busy": "2025-12-24T13:51:55.085810Z",
     "iopub.status.idle": "2025-12-24T13:51:55.773890Z",
     "shell.execute_reply": "2025-12-24T13:51:55.772783Z"
    },
    "papermill": {
     "duration": 0.699515,
     "end_time": "2025-12-24T13:51:55.775635",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.076120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.872\n",
      "Optimized RMSE: 4,807.36\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Random Forest Regressor\n",
    "RF_Bayes = RandomForestRegressor( \n",
    "    n_estimators=best_params_rf['n_estimators'], \n",
    "    max_depth=best_params_rf['max_depth'], \n",
    "    min_samples_split=best_params_rf['min_samples_split'], \n",
    "    random_state=42)\n",
    "\n",
    "RF_Bayes.fit(train_X, train_y)\n",
    "\n",
    "rf_mse_translate = -best_score_rf\n",
    "rf_rmse_translate = np.sqrt(rf_mse_translate)\n",
    "rf_preds = RF_Bayes.predict(val_X)\n",
    "rf_r2 = r2_score(val_y, rf_preds) \n",
    "\n",
    "print(f\"Optimized R²: {rf_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {rf_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1ec16",
   "metadata": {
    "papermill": {
     "duration": 0.008556,
     "end_time": "2025-12-24T13:51:55.793685",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.785129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Optimized Models Performance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e482fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:51:55.813874Z",
     "iopub.status.busy": "2025-12-24T13:51:55.813551Z",
     "iopub.status.idle": "2025-12-24T13:51:55.881640Z",
     "shell.execute_reply": "2025-12-24T13:51:55.880315Z"
    },
    "papermill": {
     "duration": 0.079824,
     "end_time": "2025-12-24T13:51:55.883295",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.803471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\n",
      "Optimized Decision Tree\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.873\n",
      "MAE: 2,420.59\n",
      "MSE: 18,311,904.31\n",
      "RMSE: 4,279.24\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.867\n",
      "MAE: 2,646.49\n",
      "MSE: 20,594,594.98\n",
      "RMSE: 4,538.13\n",
      "\u001b[4m\n",
      "Optimized Random Forest\u001b[0m\n",
      "\u001b[1mTrain:\u001b[0m\n",
      "R²: 0.924\n",
      "MAE: 1,842.33\n",
      "MSE: 10,936,379.26\n",
      "RMSE: 3,307.02\n",
      "\u001b[1m\n",
      "Validation:\u001b[0m\n",
      "R²: 0.872\n",
      "MAE: 2,542.78\n",
      "MSE: 19,878,928.21\n",
      "RMSE: 4,458.58\n"
     ]
    }
   ],
   "source": [
    "# Optimized Decision Tree ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Decision Tree\" + \"\\x1B[0m\") \n",
    "r2_odt_tr, mae_odt_tr, mse_odt_tr, rmse_odt_tr = evaluate(DT_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt_tr:.3f}\") \n",
    "print(f\"MAE: {mae_odt_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_odt_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt_tr:,.2f}\")\n",
    "\n",
    "r2_odt, mae_odt, mse_odt, rmse_odt = evaluate(DT_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_odt:.3f}\") \n",
    "print(f\"MAE: {mae_odt:,.2f}\") \n",
    "print(f\"MSE: {mse_odt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_odt:,.2f}\")\n",
    "\n",
    "# Optimized Random Forest ------------------------------\n",
    "print(\"\\x1B[4m\" + \"\\nOptimized Random Forest\" + \"\\x1B[0m\") \n",
    "r2_orf_tr, mae_orf_tr, mse_orf_tr, rmse_orf_tr = evaluate(RF_Bayes, train_X, train_y) \n",
    "print(\"\\033[1m\" + \"Train:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf_tr:.3f}\") \n",
    "print(f\"MAE: {mae_orf_tr:,.2f}\") \n",
    "print(f\"MSE: {mse_orf_tr:,.2f}\") \n",
    "print(f\"RMSE: {rmse_orf_tr:,.2f}\")\n",
    "\n",
    "r2_orf, mae_orf, mse_orf, rmse_orf = evaluate(RF_Bayes, val_X, val_y) \n",
    "print(\"\\033[1m\" + \"\\nValidation:\" + \"\\033[0m\")\n",
    "print(f\"R²: {r2_orf:.3f}\") \n",
    "print(f\"MAE: {mae_orf:,.2f}\") \n",
    "print(f\"MSE: {mse_orf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_orf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c98b2",
   "metadata": {
    "papermill": {
     "duration": 0.008861,
     "end_time": "2025-12-24T13:51:55.900871",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.892010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.5 Functions for Gradio**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bd5f6",
   "metadata": {
    "papermill": {
     "duration": 0.008606,
     "end_time": "2025-12-24T13:51:55.918131",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.909525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.51 Function 1**\n",
    "---\n",
    "Since the user will have to input categorical features alongside numerical inputs, they will have to be formatted accordingly. In this function, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc507077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:51:55.937947Z",
     "iopub.status.busy": "2025-12-24T13:51:55.937586Z",
     "iopub.status.idle": "2025-12-24T13:51:55.943838Z",
     "shell.execute_reply": "2025-12-24T13:51:55.942986Z"
    },
    "papermill": {
     "duration": 0.018219,
     "end_time": "2025-12-24T13:51:55.945270",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.927051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_input(age, sex, bmi, children, smoker, region):\n",
    "    input_row = pd.DataFrame(0, index=[0], columns=X.columns)\n",
    "\n",
    "    input_row['age'] = age\n",
    "    input_row['bmi'] = bmi\n",
    "    input_row['children'] = children\n",
    "\n",
    "    # one-hot categorical\n",
    "    col = f\"sex_{sex}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"smoker_{smoker}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"region_{region}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    return input_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c4826",
   "metadata": {
    "papermill": {
     "duration": 0.008217,
     "end_time": "2025-12-24T13:51:55.961941",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.953724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.52 Function 2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0485245d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:51:55.980318Z",
     "iopub.status.busy": "2025-12-24T13:51:55.979971Z",
     "iopub.status.idle": "2025-12-24T13:51:55.986930Z",
     "shell.execute_reply": "2025-12-24T13:51:55.986018Z"
    },
    "papermill": {
     "duration": 0.018324,
     "end_time": "2025-12-24T13:51:55.988436",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.970112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, age, sex, bmi, children, smoker, region):\n",
    "    # Dataset columns are lowercase, but user input first letters are uppercased for formatting aesthetics\n",
    "    sex = sex.lower()\n",
    "    smoker = smoker.lower()\n",
    "    region = region.lower()\n",
    "\n",
    "    # Sex, smoker, and regions are categorical strings \n",
    "    input_df = build_input(age, sex, bmi, children, smoker, region)\n",
    "    \n",
    "    if model == 'Linear Regression':\n",
    "        preds = LR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Decision Tree':\n",
    "        preds = DTR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Random Forest':\n",
    "        preds = RF.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized DT':\n",
    "        preds = DT_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized RF':\n",
    "        preds = RF_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ada4c",
   "metadata": {
    "papermill": {
     "duration": 0.008283,
     "end_time": "2025-12-24T13:51:56.005329",
     "exception": false,
     "start_time": "2025-12-24T13:51:55.997046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.6 Gradio Interface**\n",
    "---\n",
    "To use the functions through a GUI, Gradio will be used as it provides a clean interface for deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b866d22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T13:51:56.024513Z",
     "iopub.status.busy": "2025-12-24T13:51:56.024166Z",
     "iopub.status.idle": "2025-12-24T13:51:58.037860Z",
     "shell.execute_reply": "2025-12-24T13:51:58.036984Z"
    },
    "papermill": {
     "duration": 2.025699,
     "end_time": "2025-12-24T13:51:58.039510",
     "exception": false,
     "start_time": "2025-12-24T13:51:56.013811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://a29cc816c4a0b66afe.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a29cc816c4a0b66afe.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    gr.Dropdown([\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Optimized DT\", \"Optimized RF\"], value=\"Optimized RF\", label=\"Model\"),\n",
    "    gr.Number(label=\"Age\", minimum=0),\n",
    "    gr.Dropdown([\"Male\", \"Female\"], label=\"Sex\"),\n",
    "    gr.Number(label=\"BMI\"),\n",
    "    gr.Number(label=\"Number of children\"),\n",
    "    gr.Dropdown([\"No\", \"Yes\"], label=\"Smoker\"),\n",
    "    gr.Dropdown([\"Northeast\", \"Northwest\", \"Southeast\", \"Southwest\"], label=\"Location\")\n",
    "]\n",
    "\n",
    "outputs = gr.Textbox(label=\"Predicted Charge\")\n",
    "\n",
    "css = \"\"\"\n",
    ".gradio-container{\n",
    "margin-top: 3rem !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "PredictiveTool = gr.Interface(\n",
    "    fn=predict, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    title=\"Medical Insurance Cost\",\n",
    "    theme=gr.themes.Soft(), # Different theme to change the look of the tool. The blue, monochromatic palette goes well with how medical/healthcare designs are generally represented.\n",
    "    css=css\n",
    ")\n",
    "PredictiveTool.launch(height=900) # Bigger Rendered HTML height for UX design so users do not have to scroll to use the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ccbd9",
   "metadata": {
    "papermill": {
     "duration": 0.009466,
     "end_time": "2025-12-24T13:51:58.058812",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.049346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Deliverables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2a5039",
   "metadata": {
    "papermill": {
     "duration": 0.008765,
     "end_time": "2025-12-24T13:51:58.076860",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.068095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.1 Dataset Description**\n",
    "The dataset this ML problem is trained on is from the Medical Insurance Cost Dataset by Mosap Abdel-Ghany here on Kaggle (https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset). \n",
    "\n",
    "The dataset contains 1338 rows and 7 columns, with 4 numerical features and 3 categorical features. The dataset has already been cleaned beforehand so there are no invalid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ad8184",
   "metadata": {
    "papermill": {
     "duration": 0.008883,
     "end_time": "2025-12-24T13:51:58.094524",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.085641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.2 Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ad9e6",
   "metadata": {
    "papermill": {
     "duration": 0.008908,
     "end_time": "2025-12-24T13:51:58.113247",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.104339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.3 Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc898665",
   "metadata": {
    "papermill": {
     "duration": 0.008745,
     "end_time": "2025-12-24T13:51:58.130423",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.121678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.4 Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bb8e7",
   "metadata": {
    "papermill": {
     "duration": 0.009033,
     "end_time": "2025-12-24T13:51:58.148549",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.139516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.5 Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b02452",
   "metadata": {
    "papermill": {
     "duration": 0.008721,
     "end_time": "2025-12-24T13:51:58.165992",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.157271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "Initially, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd4ce7",
   "metadata": {
    "papermill": {
     "duration": 0.009135,
     "end_time": "2025-12-24T13:51:58.184011",
     "exception": false,
     "start_time": "2025-12-24T13:51:58.174876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8129551,
     "sourceId": 12853160,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 158.471334,
   "end_time": "2025-12-24T13:52:00.814123",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T13:49:22.342789",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
