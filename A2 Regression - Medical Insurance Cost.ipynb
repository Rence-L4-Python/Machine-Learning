{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152f36b2",
   "metadata": {
    "papermill": {
     "duration": 0.006181,
     "end_time": "2025-12-24T08:33:39.836810",
     "exception": false,
     "start_time": "2025-12-24T08:33:39.830629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **<span style=\"color: green;\">Predictive Regression Tool Using Gradio</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95ebe9",
   "metadata": {
    "papermill": {
     "duration": 0.004811,
     "end_time": "2025-12-24T08:33:39.846708",
     "exception": false,
     "start_time": "2025-12-24T08:33:39.841897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **1. Medical Insurance Cost **\n",
    "---\n",
    "(https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)\n",
    "\n",
    "---\n",
    "\n",
    "For Assessment 2, we are required to solve a Machine Learning problem of any type. For this project, I decided to work with a Regression Task. We were also instructed to use Gradio to work with the Machine Learning Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ddcc7",
   "metadata": {
    "papermill": {
     "duration": 0.004692,
     "end_time": "2025-12-24T08:33:39.856406",
     "exception": false,
     "start_time": "2025-12-24T08:33:39.851714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.1 Importing**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf8ab21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:39.867809Z",
     "iopub.status.busy": "2025-12-24T08:33:39.867000Z",
     "iopub.status.idle": "2025-12-24T08:33:48.973890Z",
     "shell.execute_reply": "2025-12-24T08:33:48.973028Z"
    },
    "papermill": {
     "duration": 9.114359,
     "end_time": "2025-12-24T08:33:48.975520",
     "exception": false,
     "start_time": "2025-12-24T08:33:39.861161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75909b8",
   "metadata": {
    "papermill": {
     "duration": 0.004438,
     "end_time": "2025-12-24T08:33:48.984834",
     "exception": false,
     "start_time": "2025-12-24T08:33:48.980396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.2 Printing CSV and Data Checking**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e861889e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:48.995821Z",
     "iopub.status.busy": "2025-12-24T08:33:48.994814Z",
     "iopub.status.idle": "2025-12-24T08:33:49.040845Z",
     "shell.execute_reply": "2025-12-24T08:33:49.039904Z"
    },
    "papermill": {
     "duration": 0.052906,
     "end_time": "2025-12-24T08:33:49.042236",
     "exception": false,
     "start_time": "2025-12-24T08:33:48.989330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 7)\n",
      "Index(['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic = pd.read_csv('/kaggle/input/medical-insurance-cost-dataset/insurance.csv')\n",
    "print(mic.shape)\n",
    "print(mic.columns)\n",
    "mic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1de6d4",
   "metadata": {
    "papermill": {
     "duration": 0.004918,
     "end_time": "2025-12-24T08:33:49.052315",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.047397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 1338 rows, and seven columns with the categories: age, sex, bmi, children, smoker, region, and charges. Since ML trains on numerical data, the categorical features will have to be encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780f973",
   "metadata": {
    "papermill": {
     "duration": 0.004689,
     "end_time": "2025-12-24T08:33:49.061962",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.057273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.21 Cleaning Data**\n",
    "---\n",
    "It is still good to check if any cells have missing or unsupported data. The isna().sum() functions from pandas are used together to check for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c55da18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:49.073463Z",
     "iopub.status.busy": "2025-12-24T08:33:49.072898Z",
     "iopub.status.idle": "2025-12-24T08:33:49.080194Z",
     "shell.execute_reply": "2025-12-24T08:33:49.079199Z"
    },
    "papermill": {
     "duration": 0.014758,
     "end_time": "2025-12-24T08:33:49.081472",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.066714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "bmi         0\n",
       "children    0\n",
       "smoker      0\n",
       "region      0\n",
       "charges     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5c182",
   "metadata": {
    "papermill": {
     "duration": 0.004747,
     "end_time": "2025-12-24T08:33:49.091146",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.086399",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.3 Regression Task**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b3450d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:49.102860Z",
     "iopub.status.busy": "2025-12-24T08:33:49.102090Z",
     "iopub.status.idle": "2025-12-24T08:33:49.487742Z",
     "shell.execute_reply": "2025-12-24T08:33:49.486835Z"
    },
    "papermill": {
     "duration": 0.393383,
     "end_time": "2025-12-24T08:33:49.489350",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.095967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mic.drop('charges', axis=1)\n",
    "X = pd.get_dummies(X, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "y = mic['charges']\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "LR = LinearRegression().fit(train_X, train_y)\n",
    "\n",
    "DTR = DecisionTreeRegressor().fit(train_X, train_y)\n",
    "\n",
    "RF = RandomForestRegressor().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4cefc",
   "metadata": {
    "papermill": {
     "duration": 0.00536,
     "end_time": "2025-12-24T08:33:49.499921",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.494561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.4 Model Performance & Optimization**\n",
    "---\n",
    "The accuracy of the models have to be determined to see if the tool is reliable and ready to be deployed for people to use. The provided function works with sklearn's imported functions, evaluating the different models that were previously named. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f5308f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:49.511113Z",
     "iopub.status.busy": "2025-12-24T08:33:49.510707Z",
     "iopub.status.idle": "2025-12-24T08:33:49.537656Z",
     "shell.execute_reply": "2025-12-24T08:33:49.536690Z"
    },
    "papermill": {
     "duration": 0.034163,
     "end_time": "2025-12-24T08:33:49.538946",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.504783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression\n",
      "R²: 0.784\n",
      "MAE: 4,181.19\n",
      "MSE: 33,596,915.85\n",
      "RMSE: 5,796.28\n",
      "\n",
      "Decision Tree\n",
      "R²: 0.692\n",
      "MAE: 3,426.17\n",
      "MSE: 47,839,767.53\n",
      "RMSE: 6,916.63\n",
      "\n",
      "Random Forest\n",
      "R²: 0.860\n",
      "MAE: 2,621.40\n",
      "MSE: 21,676,856.80\n",
      "RMSE: 4,655.84\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, val_X, val_y):\n",
    "    preds = model.predict(val_X)\n",
    "    r2 = r2_score(val_y, preds)\n",
    "    mae = mean_absolute_error(val_y, preds)\n",
    "    mse = mean_squared_error(val_y, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(val_y, preds))\n",
    "    return r2, mae, mse, rmse\n",
    "\n",
    "# Linear Regression \n",
    "r2_lr, mae_lr, mse_lr, rmse_lr = evaluate(LR, val_X, val_y) \n",
    "print(\"\\nLinear Regression\") \n",
    "print(f\"R²: {r2_lr:.3f}\") \n",
    "print(f\"MAE: {mae_lr:,.2f}\") \n",
    "print(f\"MSE: {mse_lr:,.2f}\")\n",
    "print(f\"RMSE: {rmse_lr:,.2f}\")\n",
    "    \n",
    "# Decision Tree \n",
    "r2_dt, mae_dt, mse_dt, rmse_dt = evaluate(DTR, val_X, val_y) \n",
    "print(\"\\nDecision Tree\") \n",
    "print(f\"R²: {r2_dt:.3f}\") \n",
    "print(f\"MAE: {mae_dt:,.2f}\") \n",
    "print(f\"MSE: {mse_dt:,.2f}\") \n",
    "print(f\"RMSE: {rmse_dt:,.2f}\")\n",
    "\n",
    "# Random Forest \n",
    "r2_rf, mae_rf, mse_rf, rmse_rf = evaluate(RF, val_X, val_y) \n",
    "print(\"\\nRandom Forest\") \n",
    "print(f\"R²: {r2_rf:.3f}\") \n",
    "print(f\"MAE: {mae_rf:,.2f}\") \n",
    "print(f\"MSE: {mse_rf:,.2f}\")\n",
    "print(f\"RMSE: {rmse_rf:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa51ed0",
   "metadata": {
    "papermill": {
     "duration": 0.004955,
     "end_time": "2025-12-24T08:33:49.549121",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.544166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.41 Optimization**\n",
    "---\n",
    "With evaluation metrics, lower values are better for MAE, MSE, and RMSE. As for the R² score, it should be higher. Out of the models evaluated so far, Random Forest had the best performance out of the box, with the Decision Tree model performing the least. The Decision Tree and Random Forest models will be optimized as they can be tuned with hyperparameters. The Bayesian Optimization library is used after installing it through the console. Bayesian Optimization was used over Grid Search and Random Search to effectively find the optimal hyperparameters for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500da59e",
   "metadata": {
    "papermill": {
     "duration": 0.004852,
     "end_time": "2025-12-24T08:33:49.558860",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.554008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41a Decision Tree Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8b534c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:49.570072Z",
     "iopub.status.busy": "2025-12-24T08:33:49.569754Z",
     "iopub.status.idle": "2025-12-24T08:33:54.794159Z",
     "shell.execute_reply": "2025-12-24T08:33:54.793403Z"
    },
    "papermill": {
     "duration": 5.232086,
     "end_time": "2025-12-24T08:33:54.795749",
     "exception": false,
     "start_time": "2025-12-24T08:33:49.563663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.46e+07\u001b[39m | \u001b[39m8.1162622\u001b[39m | \u001b[39m19.112857\u001b[39m | \u001b[39m14.907884\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-3.28e+07\u001b[39m | \u001b[39m12.374511\u001b[39m | \u001b[39m4.8083355\u001b[39m | \u001b[39m3.9638958\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.57e+07\u001b[39m | \u001b[39m2.1035886\u001b[39m | \u001b[39m17.591170\u001b[39m | \u001b[39m12.421185\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.42e+07\u001b[39m | \u001b[35m14.453378\u001b[39m | \u001b[35m2.3705208\u001b[39m | \u001b[35m19.428287\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.96e+07\u001b[39m | \u001b[39m16.816410\u001b[39m | \u001b[39m5.8221039\u001b[39m | \u001b[39m4.4546743\u001b[39m |\n",
      "| \u001b[35m6        \u001b[39m | \u001b[35m-2.39e+07\u001b[39m | \u001b[35m11.385296\u001b[39m | \u001b[35m10.542765\u001b[39m | \u001b[35m20.0     \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m14.138448\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.55e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m9.9460183\u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.42e+07\u001b[39m | \u001b[39m11.982222\u001b[39m | \u001b[39m8.9658312\u001b[39m | \u001b[39m19.883575\u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m5.4251767\u001b[39m | \u001b[39m14.584147\u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.49e+07\u001b[39m | \u001b[39m13.464222\u001b[39m | \u001b[39m13.229258\u001b[39m | \u001b[39m12.135924\u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.41e+07\u001b[39m | \u001b[39m15.859325\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m18.526555\u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.92e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m16.698567\u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.54e+07\u001b[39m | \u001b[39m11.673448\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m8.5865338\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m-2.33e+07\u001b[39m | \u001b[35m5.8154771\u001b[39m | \u001b[35m12.320651\u001b[39m | \u001b[35m10.940210\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-5.67e+07\u001b[39m | \u001b[39m1.0      \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-4.40e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m1.0      \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.48e+07\u001b[39m | \u001b[39m14.332692\u001b[39m | \u001b[39m2.0      \u001b[39m | \u001b[39m11.971412\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.62e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m12.101485\u001b[39m | \u001b[39m8.5965694\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m18.205336\u001b[39m | \u001b[39m8.1242594\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.0300918\u001b[39m | \u001b[39m16.728894\u001b[39m | \u001b[39m10.570303\u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m11.323618\u001b[39m | \u001b[39m7.4461229\u001b[39m | \u001b[39m13.089682\u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m7.5918264\u001b[39m | \u001b[39m13.326961\u001b[39m | \u001b[39m15.063144\u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m14.245678\u001b[39m | \u001b[39m20.0     \u001b[39m | \u001b[39m13.294957\u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.39e+07\u001b[39m | \u001b[39m14.769305\u001b[39m | \u001b[39m14.560632\u001b[39m | \u001b[39m20.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 10}\n",
      "Best Score (Bayesian Optimization): -23326594.469013788\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from GeeksforGeeks, using bayesian optimization (https://www.geeksforgeeks.org/machine-learning/how-to-tune-a-decision-tree-in-hyperparameter-tuning/)\n",
    "def dt_mic(max_depth, min_samples_split, min_samples_leaf):\n",
    "    estimator = DecisionTreeRegressor(\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        min_samples_leaf=int(min_samples_leaf),\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5) # Minimizing MSE is equivalent to maximizing negative-MSE\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20)\n",
    "}\n",
    "\n",
    "dt_optimizer = BayesianOptimization(\n",
    "    f=dt_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "dt_optimizer.maximize(n_iter=25, init_points=5)\n",
    "best_params_dt = dt_optimizer.max['params']\n",
    "best_params_dt['max_depth'] = int(best_params_dt['max_depth'])\n",
    "best_params_dt['min_samples_split'] = int(best_params_dt['min_samples_split'])\n",
    "best_params_dt['min_samples_leaf'] = int(best_params_dt['min_samples_leaf'])\n",
    "best_score_dt = dt_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_dt}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c15c2d",
   "metadata": {
    "papermill": {
     "duration": 0.009613,
     "end_time": "2025-12-24T08:33:54.815671",
     "exception": false,
     "start_time": "2025-12-24T08:33:54.806058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af66161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:54.836731Z",
     "iopub.status.busy": "2025-12-24T08:33:54.836155Z",
     "iopub.status.idle": "2025-12-24T08:33:54.852573Z",
     "shell.execute_reply": "2025-12-24T08:33:54.851931Z"
    },
    "papermill": {
     "duration": 0.028998,
     "end_time": "2025-12-24T08:33:54.854398",
     "exception": false,
     "start_time": "2025-12-24T08:33:54.825400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.867\n",
      "Optimized RMSE: 4,829.76\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Decision Tree Regressor\n",
    "DT_Bayes = DecisionTreeRegressor( \n",
    "    max_depth=best_params_dt['max_depth'], \n",
    "    min_samples_split=best_params_dt['min_samples_split'], \n",
    "    min_samples_leaf=best_params_dt['min_samples_leaf'], \n",
    "    random_state=42)\n",
    "\n",
    "DT_Bayes.fit(train_X, train_y)\n",
    "\n",
    "dt_mse_translate = -best_score_dt # Since the cross val score uses negative scoring, this turns it into a positive value\n",
    "dt_rmse_translate = np.sqrt(dt_mse_translate) # Square root of mse is rmse and is closer to the values used for medical insurance cost in $USD\n",
    "dt_preds = DT_Bayes.predict(val_X)\n",
    "dt_r2 = r2_score(val_y, dt_preds) \n",
    "\n",
    "print(f\"Optimized R²: {dt_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {dt_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60449e",
   "metadata": {
    "papermill": {
     "duration": 0.00974,
     "end_time": "2025-12-24T08:33:54.874354",
     "exception": false,
     "start_time": "2025-12-24T08:33:54.864614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### **1.41b Random Forest Optimization** >> (Hyperparameter Tuning)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a8105d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:33:54.887279Z",
     "iopub.status.busy": "2025-12-24T08:33:54.886814Z",
     "iopub.status.idle": "2025-12-24T08:35:55.764895Z",
     "shell.execute_reply": "2025-12-24T08:35:55.763911Z"
    },
    "papermill": {
     "duration": 120.886204,
     "end_time": "2025-12-24T08:35:55.766343",
     "exception": false,
     "start_time": "2025-12-24T08:33:54.880139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_esti... | max_depth | min_sa... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m-2.36e+07\u001b[39m | \u001b[39m249.81604\u001b[39m | \u001b[39m29.014286\u001b[39m | \u001b[39m7.8559515\u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m339.46339\u001b[39m | \u001b[39m13.120372\u001b[39m | \u001b[39m3.2479561\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m-2.38e+07\u001b[39m | \u001b[39m123.23344\u001b[39m | \u001b[39m27.323522\u001b[39m | \u001b[39m6.8089200\u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m-2.32e+07\u001b[39m | \u001b[35m383.22903\u001b[39m | \u001b[35m10.411689\u001b[39m | \u001b[35m9.7592788\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m-2.45e+07\u001b[39m | \u001b[39m432.97705\u001b[39m | \u001b[39m14.246782\u001b[39m | \u001b[39m3.4545997\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m-2.34e+07\u001b[39m | \u001b[39m383.12355\u001b[39m | \u001b[39m10.428747\u001b[39m | \u001b[39m8.6841783\u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m387.52410\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.50203\u001b[39m | \u001b[39m16.670786\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m396.41384\u001b[39m | \u001b[39m14.198882\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m395.99091\u001b[39m | \u001b[39m25.168777\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m403.23208\u001b[39m | \u001b[39m21.595070\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m387.63557\u001b[39m | \u001b[39m27.715969\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m375.82364\u001b[39m | \u001b[39m25.009127\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.24790\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m365.88791\u001b[39m | \u001b[39m18.238178\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m367.98182\u001b[39m | \u001b[39m24.949440\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m382.25633\u001b[39m | \u001b[39m22.129411\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m369.21462\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m359.87025\u001b[39m | \u001b[39m10.365589\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m354.88643\u001b[39m | \u001b[39m30.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m355.82650\u001b[39m | \u001b[39m19.782845\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m-2.37e+07\u001b[39m | \u001b[39m189.70758\u001b[39m | \u001b[39m10.207937\u001b[39m | \u001b[39m6.6337112\u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m-2.40e+07\u001b[39m | \u001b[39m499.62040\u001b[39m | \u001b[39m29.559066\u001b[39m | \u001b[39m5.2809506\u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m287.73411\u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m289.65078\u001b[39m | \u001b[39m15.960336\u001b[39m | \u001b[39m2.0068777\u001b[39m |\n",
      "| \u001b[35m26       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m278.84161\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[35m27       \u001b[39m | \u001b[35m-2.31e+07\u001b[39m | \u001b[35m268.81017\u001b[39m | \u001b[35m10.0     \u001b[39m | \u001b[35m10.0     \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m271.92727\u001b[39m | \u001b[39m18.680327\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m-2.47e+07\u001b[39m | \u001b[39m266.62652\u001b[39m | \u001b[39m15.173725\u001b[39m | \u001b[39m2.0      \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m-2.31e+07\u001b[39m | \u001b[39m374.99721\u001b[39m | \u001b[39m16.319748\u001b[39m | \u001b[39m10.0     \u001b[39m |\n",
      "=============================================================\n",
      "Best Parameters (Bayesian Optimization): {'n_estimators': 268, 'max_depth': 10, 'min_samples_split': 10}\n",
      "Best Score (Bayesian Optimization): -23110676.701853152\n"
     ]
    }
   ],
   "source": [
    "def rf_mic(n_estimators, max_depth, min_samples_split):\n",
    "    estimator = RandomForestRegressor(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        random_state=42\n",
    "    )\n",
    "    cval = cross_val_score(estimator, train_X, train_y, scoring='neg_mean_squared_error', cv=5)\n",
    "    return cval.mean()\n",
    "\n",
    "param_bounds = {\n",
    "    'n_estimators': (100, 500),\n",
    "    'max_depth': (10, 30),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "rf_optimizer = BayesianOptimization(\n",
    "    f=rf_mic,\n",
    "    pbounds=param_bounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "rf_optimizer.maximize(init_points=5, n_iter=25)\n",
    "\n",
    "best_params_rf = rf_optimizer.max['params']\n",
    "best_params_rf['n_estimators'] = int(best_params_rf['n_estimators'])\n",
    "best_params_rf['max_depth'] = int(best_params_rf['max_depth'])\n",
    "best_params_rf['min_samples_split'] = int(best_params_rf['min_samples_split'])\n",
    "best_score_rf = rf_optimizer.max['target']\n",
    "\n",
    "print(f\"Best Parameters (Bayesian Optimization): {best_params_rf}\")\n",
    "print(f\"Best Score (Bayesian Optimization): {best_score_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fd1cb",
   "metadata": {
    "papermill": {
     "duration": 0.007152,
     "end_time": "2025-12-24T08:35:55.781006",
     "exception": false,
     "start_time": "2025-12-24T08:35:55.773854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Adapting for model use\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41270d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:35:55.796431Z",
     "iopub.status.busy": "2025-12-24T08:35:55.796153Z",
     "iopub.status.idle": "2025-12-24T08:35:56.429415Z",
     "shell.execute_reply": "2025-12-24T08:35:56.428458Z"
    },
    "papermill": {
     "duration": 0.642944,
     "end_time": "2025-12-24T08:35:56.430921",
     "exception": false,
     "start_time": "2025-12-24T08:35:55.787977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized R²: 0.872\n",
      "Optimized RMSE: 4,807.36\n"
     ]
    }
   ],
   "source": [
    "# Using the values found in the Bayesian Optimization process as hyperparameters for Random Forest Regressor\n",
    "RF_Bayes = RandomForestRegressor( \n",
    "    n_estimators=best_params_rf['n_estimators'], \n",
    "    max_depth=best_params_rf['max_depth'], \n",
    "    min_samples_split=best_params_rf['min_samples_split'], \n",
    "    random_state=42)\n",
    "\n",
    "RF_Bayes.fit(train_X, train_y)\n",
    "\n",
    "rf_mse_translate = -best_score_rf\n",
    "rf_rmse_translate = np.sqrt(rf_mse_translate)\n",
    "rf_preds = RF_Bayes.predict(val_X)\n",
    "rf_r2 = r2_score(val_y, rf_preds) \n",
    "\n",
    "print(f\"Optimized R²: {rf_r2:,.3f}\")\n",
    "print(f\"Optimized RMSE: {rf_rmse_translate:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d55a9f",
   "metadata": {
    "papermill": {
     "duration": 0.007194,
     "end_time": "2025-12-24T08:35:56.445544",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.438350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.5 Functions for Gradio**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc92b3",
   "metadata": {
    "papermill": {
     "duration": 0.007077,
     "end_time": "2025-12-24T08:35:56.459773",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.452696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.51 Function 1**\n",
    "---\n",
    "Since the user will have to input categorical features alongside numerical inputs, they will have to be formatted accordingly. In this function, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b11ab9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:35:56.475235Z",
     "iopub.status.busy": "2025-12-24T08:35:56.474935Z",
     "iopub.status.idle": "2025-12-24T08:35:56.480391Z",
     "shell.execute_reply": "2025-12-24T08:35:56.479687Z"
    },
    "papermill": {
     "duration": 0.01492,
     "end_time": "2025-12-24T08:35:56.481690",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.466770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_input(age, sex, bmi, children, smoker, region):\n",
    "    input_row = pd.DataFrame(0, index=[0], columns=X.columns)\n",
    "\n",
    "    input_row['age'] = age\n",
    "    input_row['bmi'] = bmi\n",
    "    input_row['children'] = children\n",
    "\n",
    "    # one-hot categorical\n",
    "    col = f\"sex_{sex}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"smoker_{smoker}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    col = f\"region_{region}\"\n",
    "    if col in input_row.columns:\n",
    "        input_row[col] = 1\n",
    "\n",
    "    return input_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ed1dc9",
   "metadata": {
    "papermill": {
     "duration": 0.007348,
     "end_time": "2025-12-24T08:35:56.496524",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.489176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### **1.52 Function 2**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a42e9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:35:56.513018Z",
     "iopub.status.busy": "2025-12-24T08:35:56.512256Z",
     "iopub.status.idle": "2025-12-24T08:35:56.518484Z",
     "shell.execute_reply": "2025-12-24T08:35:56.517741Z"
    },
    "papermill": {
     "duration": 0.016112,
     "end_time": "2025-12-24T08:35:56.520015",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.503903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, age, sex, bmi, children, smoker, region):\n",
    "    # Dataset columns are lowercase, but user input first letters are uppercased for formatting aesthetics\n",
    "    sex = sex.lower()\n",
    "    smoker = smoker.lower()\n",
    "    region = region.lower()\n",
    "\n",
    "    # Sex, smoker, and regions are categorical strings \n",
    "    input_df = build_input(age, sex, bmi, children, smoker, region)\n",
    "    \n",
    "    if model == 'Linear Regression':\n",
    "        preds = LR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Decision Tree':\n",
    "        preds = DTR.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Random Forest':\n",
    "        preds = RF.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized DT':\n",
    "        preds = DT_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\"\n",
    "    elif model == 'Optimized RF':\n",
    "        preds = RF_Bayes.predict(input_df)[0]\n",
    "        return f\"${preds:,.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb091f3a",
   "metadata": {
    "papermill": {
     "duration": 0.007541,
     "end_time": "2025-12-24T08:35:56.535091",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.527550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **1.6 Gradio Interface**\n",
    "---\n",
    "To use the functions through a GUI, Gradio will be used as it provides a clean interface for deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1bbfb66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T08:35:56.550788Z",
     "iopub.status.busy": "2025-12-24T08:35:56.550471Z",
     "iopub.status.idle": "2025-12-24T08:35:58.622095Z",
     "shell.execute_reply": "2025-12-24T08:35:58.621293Z"
    },
    "papermill": {
     "duration": 2.081337,
     "end_time": "2025-12-24T08:35:58.623531",
     "exception": false,
     "start_time": "2025-12-24T08:35:56.542194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://a05f7ee0f8dfd4f5c1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a05f7ee0f8dfd4f5c1.gradio.live\" width=\"100%\" height=\"900\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    gr.Dropdown([\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Optimized DT\", \"Optimized RF\"], value=\"Optimized RF\", label=\"Model\"),\n",
    "    gr.Number(label=\"Age\", minimum=0),\n",
    "    gr.Dropdown([\"Male\", \"Female\"], label=\"Sex\"),\n",
    "    gr.Number(label=\"BMI\"),\n",
    "    gr.Number(label=\"Number of children\"),\n",
    "    gr.Dropdown([\"No\", \"Yes\"], label=\"Smoker\"),\n",
    "    gr.Dropdown([\"Northeast\", \"Northwest\", \"Southeast\", \"Southwest\"], label=\"Location\")\n",
    "]\n",
    "\n",
    "outputs = gr.Textbox(label=\"Predicted Charge\")\n",
    "\n",
    "PredictiveTool = gr.Interface(\n",
    "    fn=predict, \n",
    "    inputs=inputs, \n",
    "    outputs=outputs, \n",
    "    title=\"Medical Insurance Cost\",\n",
    "    theme=gr.themes.Soft() # Different theme to change the look of the tool. The blue, monochromatic palette goes well with how medical/healthcare designs are generally represented.\n",
    ")\n",
    "PredictiveTool.launch(height=900) # Bigger Rendered HTML height for UX design so users do not have to scroll to use the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c51d9b",
   "metadata": {
    "papermill": {
     "duration": 0.007748,
     "end_time": "2025-12-24T08:35:58.639142",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.631394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Deliverables**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90eaf73",
   "metadata": {
    "papermill": {
     "duration": 0.011363,
     "end_time": "2025-12-24T08:35:58.660118",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.648755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.1 Dataset Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a721e",
   "metadata": {
    "papermill": {
     "duration": 0.007419,
     "end_time": "2025-12-24T08:35:58.675161",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.667742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.2 Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa194ab",
   "metadata": {
    "papermill": {
     "duration": 0.007468,
     "end_time": "2025-12-24T08:35:58.691211",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.683743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.3 Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eea867",
   "metadata": {
    "papermill": {
     "duration": 0.007314,
     "end_time": "2025-12-24T08:35:58.706062",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.698748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.4 Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a49bb8b",
   "metadata": {
    "papermill": {
     "duration": 0.007335,
     "end_time": "2025-12-24T08:35:58.721055",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.713720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.5 Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca002024",
   "metadata": {
    "papermill": {
     "duration": 0.007208,
     "end_time": "2025-12-24T08:35:58.735717",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.728509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **2.6 Critical Reflection**\n",
    "---\n",
    "\n",
    "Initially, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b35906",
   "metadata": {
    "papermill": {
     "duration": 0.007492,
     "end_time": "2025-12-24T08:35:58.751383",
     "exception": false,
     "start_time": "2025-12-24T08:35:58.743891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8129551,
     "sourceId": 12853160,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 146.054425,
   "end_time": "2025-12-24T08:36:01.378413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T08:33:35.323988",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
